{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "823b5173",
   "metadata": {},
   "source": [
    "# metadata.csv ë¶„ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b79097d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "\n",
      "frames_done:\n",
      "----------------------------------------\n",
      "  True: 1152\n",
      "  Total: 1152\n",
      "\n",
      "sapiens_done:\n",
      "----------------------------------------\n",
      "  True: 1152\n",
      "  Total: 1152\n",
      "\n",
      "reextract_done:\n",
      "----------------------------------------\n",
      "  True: 1152\n",
      "  Total: 1152\n",
      "\n",
      "overlay_done:\n",
      "----------------------------------------\n",
      "  True: 1152\n",
      "  Total: 1152\n",
      "\n",
      "============================================================\n",
      "\n",
      "ìš”ì•½ í…Œì´ë¸”:\n",
      "------------------------------------------------------------\n",
      "                True\n",
      "frames_done     1152\n",
      "sapiens_done    1152\n",
      "reextract_done  1152\n",
      "overlay_done    1152\n"
     ]
    }
   ],
   "source": [
    "# Repetition Counter ì‹¤í—˜\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv(\"/workspace/nas203/ds_RehabilitationMedicineData/IDs/tojihoo/ASAN_01_Repeatition_Counter/data/metadata.csv\")\n",
    "\n",
    "# ê° ì»¬ëŸ¼ì˜ True/False ê°œìˆ˜ ì„¸ê¸°\n",
    "columns_to_check = ['frames_done', 'sapiens_done', 'reextract_done', 'overlay_done']\n",
    "\n",
    "print(\"=\" * 60)\n",
    "for col in columns_to_check:\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(\"-\" * 40)\n",
    "    counts = df[col].value_counts()\n",
    "    for value, count in counts.items():\n",
    "        print(f\"  {value}: {count}\")\n",
    "    print(f\"  Total: {len(df)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "# ìš”ì•½ í…Œì´ë¸”\n",
    "print(\"\\nìš”ì•½ í…Œì´ë¸”:\")\n",
    "print(\"-\" * 60)\n",
    "summary = pd.DataFrame({\n",
    "    col: df[col].value_counts() for col in columns_to_check\n",
    "}).T.fillna(0).astype(int)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c85500",
   "metadata": {},
   "source": [
    "# Keypoints ë° angle ì¢Œí‘œ ì‹œê°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e08af8af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - Total training samples: 83\n",
      "INFO - --------------------------------------------------\n",
      "INFO - Plotting trajectory for activity: frontal__biceps_curl (Found 3 samples)\n",
      "INFO - Analyzing sample: frontal__biceps_curl...\n",
      "WARNING - Path does not exist: /workspace/nas203/ds_RehabilitationMedicineData/IDs/Kimjihoo/3_project_HCCmove/data/4_INTERP_DATA/AI_dataset/N01/N01_Treatment/frontal__biceps_curl\n",
      "WARNING - Cannot plot: keypoints sequence is empty or invalid for frontal__biceps_curl\n",
      "INFO - --------------------------------------------------\n",
      "INFO - Trajectory analysis complete.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "# ë¡œê¹… ì„¤ì • (ì´ì „ê³¼ ë™ì¼)\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s - %(message)s')\n",
    "\n",
    "# --- 1. ë©”íƒ€ë°ì´í„° ë¡œë“œ ë° JSON ë¡œë“œ í•¨ìˆ˜ (ì´ì „ê³¼ ë™ì¼) ---\n",
    "\n",
    "# ì‹¤ì œ íŒŒì¼ ê²½ë¡œì— ë§ê²Œ ë¡œë“œ\n",
    "df = pd.read_csv(\"/workspace/nas203/ds_RehabilitationMedicineData/IDs/tojihoo/ASAN_01_Repeatition_Counter/data/metadata.csv\")\n",
    "train_df = df[df['is_train'] == True].copy()\n",
    "logging.info(f\"Total training samples: {len(train_df)}\")\n",
    "\n",
    "# JSON ë¡œë“œ í•¨ìˆ˜ëŠ” ì´ì „ê³¼ ë™ì¼í•˜ê²Œ ìœ ì§€í•©ë‹ˆë‹¤.\n",
    "def load_keypoints_from_directory(json_dir):\n",
    "    try:\n",
    "        json_path = Path(json_dir)\n",
    "        \n",
    "        if not json_path.exists():\n",
    "            logging.warning(f\"Path does not exist: {json_dir}\")\n",
    "            return None\n",
    "        \n",
    "        json_files = sorted([f for f in json_path.glob('*.json')])\n",
    "        \n",
    "        if len(json_files) == 0:\n",
    "            logging.warning(f\"No JSON files found in: {json_dir}\")\n",
    "            return None\n",
    "        \n",
    "        keypoints_sequence = []\n",
    "        for json_file in json_files:\n",
    "            try:\n",
    "                with open(json_file, 'r') as f:\n",
    "                    frame_data = json.load(f)\n",
    "                keypoints_sequence.append(frame_data)\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error loading {json_file}: {e}\")\n",
    "                keypoints_sequence.append(None)\n",
    "        \n",
    "        logging.info(f\" Â Loaded {len(keypoints_sequence)} frames from {json_path.name}\")\n",
    "        return keypoints_sequence\n",
    "        \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error loading from {json_dir}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# --- 2. Keypoints ì¢Œí‘œ ì¶”ì¶œ ë° ì‹œê°í™” í•¨ìˆ˜ (X-Y ì¢Œí‘œ ë™ì‹œ í”Œë¡¯) ---\n",
    "\n",
    "def plot_filtered_keypoint_trajectory_xy(keypoints_sequence, sample_name):\n",
    "    \"\"\"\n",
    "    Keypoint ì¸ë±ìŠ¤ 0~4ë¥¼ ì œì™¸í•œ ê´€ì ˆì˜ X, Y ì¢Œí‘œ ë³€í™”ë¥¼ ë¶„ë¦¬ëœ ì„œë¸Œí”Œë¡¯ìœ¼ë¡œ ì‹œê°í™”í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    if not keypoints_sequence or not keypoints_sequence[0]:\n",
    "        logging.warning(f\"Cannot plot: keypoints sequence is empty or invalid for {sample_name}\")\n",
    "        return\n",
    "\n",
    "    first_valid_frame = next((frame for frame in keypoints_sequence if frame and 'instance_info' in frame and len(frame['instance_info']) > 0), None)\n",
    "    \n",
    "    if not first_valid_frame or 'keypoints' not in first_valid_frame['instance_info'][0]:\n",
    "        logging.warning(f\"No valid keypoint data found in 'instance_info' for {sample_name}. Check JSON keys.\")\n",
    "        return\n",
    "\n",
    "    num_keypoints = first_valid_frame['meta_info']['num_keypoints']\n",
    "    keypoint_id2name = first_valid_frame['meta_info']['keypoint_id2name']\n",
    "    \n",
    "    # ğŸš¨ í•„í„°ë§í•  Keypoint ì¸ë±ìŠ¤ (0, 1, 2, 3, 4)\n",
    "    EXCLUDE_INDICES = set(range(5))\n",
    "    \n",
    "    trajectories = {i: {'x': [], 'y': []} for i in range(num_keypoints) if i not in EXCLUDE_INDICES}\n",
    "    num_frames = len(keypoints_sequence)\n",
    "    \n",
    "    # 2-1. í”„ë ˆì„ë³„ ì¢Œí‘œ ì¶”ì¶œ\n",
    "    for frame_data in keypoints_sequence:\n",
    "        keypoints_array = None\n",
    "        if (frame_data and 'instance_info' in frame_data and \n",
    "            len(frame_data['instance_info']) > 0 and \n",
    "            'keypoints' in frame_data['instance_info'][0]):\n",
    "            \n",
    "            keypoints_list = frame_data['instance_info'][0]['keypoints']\n",
    "            keypoints_array = np.array(keypoints_list) \n",
    "\n",
    "        for index in range(num_keypoints):\n",
    "            if index in EXCLUDE_INDICES:\n",
    "                continue\n",
    "\n",
    "            if keypoints_array is not None and index < len(keypoints_array) and keypoints_array.ndim >= 2:\n",
    "                # X (0), Y (1) ì¢Œí‘œë¥¼ ì¶”ì¶œ\n",
    "                trajectories[index]['x'].append(keypoints_array[index, 0])\n",
    "                trajectories[index]['y'].append(keypoints_array[index, 1])\n",
    "            else:\n",
    "                trajectories[index]['x'].append(np.nan)\n",
    "                trajectories[index]['y'].append(np.nan)\n",
    "\n",
    "    # 2-2. ì‹œê°í™” (X ë° Y ì¢Œí‘œ)\n",
    "    frames = np.arange(num_frames)\n",
    "    \n",
    "    # 2í–‰ 1ì—´ ì„œë¸Œí”Œë¡¯ ìƒì„±\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(18, 12), sharex=True)\n",
    "    fig.suptitle(f\"Keypoint Trajectories (Filtered 5-16) for Sample: {sample_name}\", fontsize=18)\n",
    "    \n",
    "    # X ì¢Œí‘œ (ìˆ˜í‰ ì´ë™) í”Œë¡¯\n",
    "    ax_x = axes[0]\n",
    "    ax_x.set_title(\"X Coordinate Over Frames (Horizontal Movement)\")\n",
    "    for index, data in trajectories.items():\n",
    "        keypoint_name = keypoint_id2name.get(str(index), f\"KP_{index}\")\n",
    "        ax_x.plot(frames, data['x'], label=keypoint_name, alpha=0.7, linewidth=1.5)\n",
    "        \n",
    "    ax_x.set_ylabel(\"X Coordinate\")\n",
    "    ax_x.grid(True, linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Y ì¢Œí‘œ (ìˆ˜ì§ ì´ë™) í”Œë¡¯\n",
    "    ax_y = axes[1]\n",
    "    ax_y.set_title(\"Y Coordinate Over Frames (Vertical Movement)\")\n",
    "    for index, data in trajectories.items():\n",
    "        keypoint_name = keypoint_id2name.get(str(index), f\"KP_{index}\")\n",
    "        ax_y.plot(frames, data['y'], label=keypoint_name, alpha=0.7, linewidth=1.5)\n",
    "        \n",
    "    ax_y.set_xlabel(\"Frame Number\")\n",
    "    ax_y.set_ylabel(\"Y Coordinate\")\n",
    "    ax_y.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "    # ë²”ë¡€ëŠ” í•˜ë‚˜ë§Œ ìƒì„±í•˜ê³  ì „ì²´ ê·¸ë¦¼ ì™¸ë¶€ì— ë°°ì¹˜\n",
    "    handles, labels = ax_x.get_legend_handles_labels()\n",
    "    fig.legend(handles, labels, loc='center right', bbox_to_anchor=(1.0, 0.5), ncol=1, fontsize=9)\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0, 0.9, 1]) # ë²”ë¡€ë¥¼ ìœ„í•´ ê³µê°„ í™•ë³´\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# --- 3. ë°ì´í„°í”„ë ˆì„ ìˆœíšŒ ë° í”Œë¡¯ ì‹¤í–‰ (ê²½ë¡œ ê¸°ë°˜ í•„í„°ë§) ---\n",
    "\n",
    "TARGET_ACTIVITY_NAME = 'frontal__biceps_curl' \n",
    "TARGET_ACTIVITY_PATH_PATTERN = f'/{TARGET_ACTIVITY_NAME}'\n",
    "\n",
    "# ê²½ë¡œ ê¸°ë°˜ í•„í„°ë§\n",
    "target_df = train_df[train_df['interp_json_path'].str.contains(TARGET_ACTIVITY_PATH_PATTERN, case=False, na=False)].copy()\n",
    "\n",
    "logging.info(\"-\" * 50)\n",
    "logging.info(f\"Plotting trajectory for activity: {TARGET_ACTIVITY_NAME} (Found {len(target_df)} samples)\")\n",
    "\n",
    "NUM_SAMPLES_TO_PLOT = 1 \n",
    "\n",
    "if len(target_df) == 0:\n",
    "    logging.warning(f\"No samples found for activity: {TARGET_ACTIVITY_NAME}\")\n",
    "else:\n",
    "    for idx, row in target_df.head(NUM_SAMPLES_TO_PLOT).iterrows():\n",
    "        json_dir = row['interp_json_path']\n",
    "        sample_name = Path(json_dir).name\n",
    "        \n",
    "        logging.info(f\"Analyzing sample: {sample_name}...\")\n",
    "        \n",
    "        keypoints_sequence = load_keypoints_from_directory(json_dir)\n",
    "        \n",
    "        # ğŸš¨ X-Y ì¢Œí‘œ ë™ì‹œ í”Œë¡¯ í•¨ìˆ˜ í˜¸ì¶œ\n",
    "        plot_filtered_keypoint_trajectory_xy(keypoints_sequence, sample_name)\n",
    "\n",
    "logging.info(\"-\" * 50)\n",
    "logging.info(\"Trajectory analysis complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f2ae735",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - Total training samples: 83\n",
      "INFO - --------------------------------------------------\n",
      "INFO - Plotting 2D Trajectory for activity: frontal__biceps_curl (Found 3 samples)\n",
      "INFO - Analyzing sample: frontal__biceps_curl...\n",
      "WARNING - No JSON files found in: /workspace/nas203/ds_RehabilitationMedicineData/IDs/Kimjihoo/3_project_HCCmove/data/4_INTERP_DATA/AI_dataset/N01/N01_Treatment/frontal__biceps_curl\n",
      "WARNING - Cannot plot: keypoints sequence is empty or invalid for frontal__biceps_curl\n",
      "INFO - --------------------------------------------------\n",
      "INFO - Trajectory analysis complete.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "# ë¡œê¹… ì„¤ì • (ì´ì „ê³¼ ë™ì¼)\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s - %(message)s')\n",
    "\n",
    "# --- 1. ë©”íƒ€ë°ì´í„° ë¡œë“œ ë° JSON ë¡œë“œ í•¨ìˆ˜ (ì´ì „ê³¼ ë™ì¼) ---\n",
    "\n",
    "df = pd.read_csv(\"/workspace/nas203/ds_RehabilitationMedicineData/IDs/tojihoo/ASAN_01_Repeatition_Counter/data/metadata.csv\")\n",
    "train_df = df[df['is_train'] == True].copy()\n",
    "logging.info(f\"Total training samples: {len(train_df)}\")\n",
    "\n",
    "# JSON ë¡œë“œ í•¨ìˆ˜ëŠ” ì´ì „ê³¼ ë™ì¼í•˜ê²Œ ìœ ì§€í•©ë‹ˆë‹¤.\n",
    "def load_keypoints_from_directory(json_dir):\n",
    "    try:\n",
    "        json_path = Path(json_dir)\n",
    "        # ... (ì¤‘ëµ: íŒŒì¼ ë¡œë“œ ë¡œì§) ...\n",
    "        json_files = sorted([f for f in json_path.glob('*.json')])\n",
    "        if len(json_files) == 0:\n",
    "            logging.warning(f\"No JSON files found in: {json_dir}\")\n",
    "            return None\n",
    "        \n",
    "        keypoints_sequence = []\n",
    "        for json_file in json_files:\n",
    "            try:\n",
    "                with open(json_file, 'r') as f:\n",
    "                    frame_data = json.load(f)\n",
    "                keypoints_sequence.append(frame_data)\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error loading {json_file}: {e}\")\n",
    "                keypoints_sequence.append(None)\n",
    "        \n",
    "        logging.info(f\" Â Loaded {len(keypoints_sequence)} frames from {json_path.name}\")\n",
    "        return keypoints_sequence\n",
    "        \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error loading from {json_dir}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# --- 2. Keypoints ì¢Œí‘œ ì¶”ì¶œ ë° ê¶¤ì  í”Œë¡¯ í•¨ìˆ˜ (Yì¶• ë°˜ì „ ì ìš©) ---\n",
    "\n",
    "def plot_keypoint_path_xy_corrected(keypoints_sequence, sample_name):\n",
    "    \"\"\"\n",
    "    Keypoint 5~16ë²ˆì˜ X vs Y ê¶¤ì ì„ 2ì°¨ì› í‰ë©´ì— ì‹œê°í™”í•©ë‹ˆë‹¤. (Yì¶• ë°˜ì „ ì ìš©)\n",
    "    \"\"\"\n",
    "    if not keypoints_sequence or not keypoints_sequence[0]:\n",
    "        logging.warning(f\"Cannot plot: keypoints sequence is empty or invalid for {sample_name}\")\n",
    "        return\n",
    "\n",
    "    first_valid_frame = next((frame for frame in keypoints_sequence if frame and 'instance_info' in frame and len(frame['instance_info']) > 0), None)\n",
    "    \n",
    "    if not first_valid_frame or 'keypoints' not in first_valid_frame['instance_info'][0]:\n",
    "        logging.warning(f\"No valid keypoint data found in 'instance_info' for {sample_name}. Check JSON keys.\")\n",
    "        return\n",
    "\n",
    "    num_keypoints = first_valid_frame['meta_info']['num_keypoints']\n",
    "    keypoint_id2name = first_valid_frame['meta_info']['keypoint_id2name']\n",
    "    \n",
    "    # í•„í„°ë§í•  Keypoint ì¸ë±ìŠ¤ (0, 1, 2, 3, 4) ì œì™¸\n",
    "    EXCLUDE_INDICES = set(range(5))\n",
    "    \n",
    "    trajectories = {i: {'x': [], 'y': []} for i in range(num_keypoints) if i not in EXCLUDE_INDICES}\n",
    "    \n",
    "    # 2-1. í”„ë ˆì„ë³„ ì¢Œí‘œ ì¶”ì¶œ\n",
    "    for frame_data in keypoints_sequence:\n",
    "        keypoints_array = None\n",
    "        if (frame_data and 'instance_info' in frame_data and \n",
    "            len(frame_data['instance_info']) > 0 and \n",
    "            'keypoints' in frame_data['instance_info'][0]):\n",
    "            \n",
    "            keypoints_list = frame_data['instance_info'][0]['keypoints']\n",
    "            keypoints_array = np.array(keypoints_list) \n",
    "\n",
    "        for index in range(num_keypoints):\n",
    "            if index in EXCLUDE_INDICES:\n",
    "                continue\n",
    "\n",
    "            if keypoints_array is not None and index < len(keypoints_array) and keypoints_array.ndim >= 2:\n",
    "                trajectories[index]['x'].append(keypoints_array[index, 0])\n",
    "                trajectories[index]['y'].append(keypoints_array[index, 1])\n",
    "            else:\n",
    "                trajectories[index]['x'].append(np.nan)\n",
    "                trajectories[index]['y'].append(np.nan)\n",
    "\n",
    "    # 2-2. ì‹œê°í™” (X vs Y ê¶¤ì )\n",
    "    fig, ax = plt.subplots(figsize=(12, 12))\n",
    "    ax.set_title(f\"2D Keypoint Trajectory (X vs Y) - Corrected Y-axis\\nSample: {sample_name}\", fontsize=16)\n",
    "    \n",
    "    for index, data in trajectories.items():\n",
    "        keypoint_name = keypoint_id2name.get(str(index), f\"KP_{index}\")\n",
    "        \n",
    "        # X vs Y ê¶¤ì ì„ ë¼ì¸ í”Œë¡¯ìœ¼ë¡œ ê·¸ë¦½ë‹ˆë‹¤.\n",
    "        ax.plot(data['x'], data['y'], \n",
    "                label=keypoint_name, \n",
    "                alpha=0.7, \n",
    "                linewidth=2.0)\n",
    "\n",
    "    ax.set_xlabel(\"X Coordinate (Horizontal)\")\n",
    "    ax.set_ylabel(\"Y Coordinate (Vertical, Up is Positive)\") \n",
    "    \n",
    "    # ğŸš¨ Yì¶• ë°˜ì „ ì ìš©: ì´ë¯¸ì§€ ì¢Œí‘œê³„ë¥¼ ì¼ë°˜ì ì¸ ì¢Œí‘œê³„ë¡œ ë³€í™˜\n",
    "    ax.invert_yaxis()\n",
    "    \n",
    "    # Xì™€ Y ì¶• ë¹„ìœ¨ì„ ê°™ê²Œ ë§Œë“¤ì–´ ê¶¤ì ì˜ ì‹¤ì œ ëª¨ì–‘ì„ ë³´ì¡´í•©ë‹ˆë‹¤.\n",
    "    ax.set_aspect('equal', adjustable='box') \n",
    "    \n",
    "    ax.legend(loc='center left', bbox_to_anchor=(1.05, 0.5), ncol=1, fontsize=10) \n",
    "    ax.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# --- 3. ë°ì´í„°í”„ë ˆì„ ìˆœíšŒ ë° í”Œë¡¯ ì‹¤í–‰ (ê²½ë¡œ ê¸°ë°˜ í•„í„°ë§) ---\n",
    "\n",
    "TARGET_ACTIVITY_NAME = 'frontal__biceps_curl' \n",
    "TARGET_ACTIVITY_PATH_PATTERN = f'/{TARGET_ACTIVITY_NAME}'\n",
    "\n",
    "# ê²½ë¡œ ê¸°ë°˜ í•„í„°ë§\n",
    "target_df = train_df[train_df['interp_json_path'].str.contains(TARGET_ACTIVITY_PATH_PATTERN, case=False, na=False)].copy()\n",
    "\n",
    "logging.info(\"-\" * 50)\n",
    "logging.info(f\"Plotting 2D Trajectory for activity: {TARGET_ACTIVITY_NAME} (Found {len(target_df)} samples)\")\n",
    "\n",
    "NUM_SAMPLES_TO_PLOT = 1 \n",
    "\n",
    "if len(target_df) == 0:\n",
    "    logging.warning(f\"No samples found for activity: {TARGET_ACTIVITY_NAME}\")\n",
    "else:\n",
    "    for idx, row in target_df.head(NUM_SAMPLES_TO_PLOT).iterrows():\n",
    "        json_dir = row['interp_json_path']\n",
    "        sample_name = Path(json_dir).name\n",
    "        \n",
    "        logging.info(f\"Analyzing sample: {sample_name}...\")\n",
    "        \n",
    "        keypoints_sequence = load_keypoints_from_directory(json_dir)\n",
    "        \n",
    "        # ğŸš¨ ìˆ˜ì •ëœ ê¶¤ì  í”Œë¡¯ í•¨ìˆ˜ í˜¸ì¶œ\n",
    "        plot_keypoint_path_xy_corrected(keypoints_sequence, sample_name)\n",
    "\n",
    "logging.info(\"-\" * 50)\n",
    "logging.info(\"Trajectory analysis complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7172a2b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - Total training samples: 83\n",
      "INFO - --------------------------------------------------\n",
      "INFO - Plotting Angle Trajectories for activity: frontal__biceps_curl (Found 3 samples)\n",
      "INFO - Analyzing sample: frontal__biceps_curl...\n",
      "INFO -  Â Loaded 0 frames from frontal__biceps_curl\n",
      "WARNING - Cannot plot: keypoints sequence is empty or invalid for frontal__biceps_curl\n",
      "INFO - --------------------------------------------------\n",
      "INFO - Trajectory analysis complete.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import logging\n",
    "import math\n",
    "\n",
    "# ë¡œê¹… ì„¤ì •\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s - %(message)s')\n",
    "\n",
    "# --- 0. ê°ë„ ê³„ì‚° ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ---\n",
    "\n",
    "def calculate_angle(p1, p2, p3):\n",
    "    \"\"\"\n",
    "    ì„¸ ì  p1(start), p2(center), p3(end)ì„ ì´ìš©í•˜ì—¬ p2ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ í•˜ëŠ” ê°ë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.\n",
    "    p1, p2, p3ëŠ” [x, y] í˜•íƒœì˜ ë¦¬ìŠ¤íŠ¸/ë°°ì—´ì´ì–´ì•¼ í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        p1 = np.array(p1)\n",
    "        p2 = np.array(p2)\n",
    "        p3 = np.array(p3)\n",
    "\n",
    "        # ë²¡í„° BA (p1 -> p2)\n",
    "        # Bë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ Aì™€ Cë¡œ í–¥í•˜ëŠ” ë²¡í„°ë¥¼ ì‚¬ìš©í•´ì•¼ p2ì—ì„œì˜ ê°ë„ë¥¼ ì–»ìŠµë‹ˆë‹¤.\n",
    "        # ë²¡í„° p2p1 (A)\n",
    "        vec_a = p1 - p2\n",
    "        # ë²¡í„° p2p3 (C)\n",
    "        vec_c = p3 - p2\n",
    "\n",
    "        # ë‚´ì  (Dot Product)\n",
    "        dot_product = np.dot(vec_a, vec_c)\n",
    "        \n",
    "        # ë²¡í„° í¬ê¸° (Norm)\n",
    "        norm_a = np.linalg.norm(vec_a)\n",
    "        norm_c = np.linalg.norm(vec_c)\n",
    "        \n",
    "        if norm_a == 0 or norm_c == 0:\n",
    "            return np.nan # ê¸¸ì´ê°€ 0ì¸ ë²¡í„°ëŠ” ê³„ì‚° ë¶ˆê°€\n",
    "        \n",
    "        # ì½”ì‚¬ì¸ ê°’ ê³„ì‚°\n",
    "        cosine_angle = dot_product / (norm_a * norm_c)\n",
    "        \n",
    "        # arccos ë²”ìœ„ ì œí•œ [-1, 1] (ë¶€ë™ ì†Œìˆ˜ì  ì˜¤ë¥˜ ë°©ì§€)\n",
    "        cosine_angle = np.clip(cosine_angle, -1.0, 1.0)\n",
    "        \n",
    "        # ë¼ë””ì•ˆ -> ê°ë„ (180ë„)\n",
    "        angle_rad = np.arccos(cosine_angle)\n",
    "        angle_deg = np.degrees(angle_rad)\n",
    "        \n",
    "        return angle_deg\n",
    "\n",
    "    except Exception:\n",
    "        return np.nan # ê³„ì‚° ì¤‘ ì˜¤ë¥˜ ë°œìƒ\n",
    "\n",
    "# --- 1. ë©”íƒ€ë°ì´í„° ë¡œë“œ ë° JSON ë¡œë“œ í•¨ìˆ˜ (ì´ì „ê³¼ ë™ì¼) ---\n",
    "\n",
    "df = pd.read_csv(\"/workspace/nas203/ds_RehabilitationMedicineData/IDs/tojihoo/ASAN_01_Repeatition_Counter/data/metadata.csv\")\n",
    "train_df = df[df['is_train'] == True].copy()\n",
    "logging.info(f\"Total training samples: {len(train_df)}\")\n",
    "\n",
    "# JSON ë¡œë“œ í•¨ìˆ˜ëŠ” ì´ì „ê³¼ ë™ì¼í•˜ê²Œ ìœ ì§€í•©ë‹ˆë‹¤.\n",
    "def load_keypoints_from_directory(json_dir):\n",
    "    # ... (ì´ì „ ì½”ë“œì™€ ë™ì¼, ìƒëµ) ...\n",
    "    try:\n",
    "        json_path = Path(json_dir)\n",
    "        # ... (ì¤‘ëµ) ...\n",
    "        json_files = sorted([f for f in json_path.glob('*.json')])\n",
    "        # ... (ì¤‘ëµ) ...\n",
    "        \n",
    "        keypoints_sequence = []\n",
    "        for json_file in json_files:\n",
    "            try:\n",
    "                with open(json_file, 'r') as f:\n",
    "                    frame_data = json.load(f)\n",
    "                keypoints_sequence.append(frame_data)\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error loading {json_file}: {e}\")\n",
    "                keypoints_sequence.append(None)\n",
    "        \n",
    "        logging.info(f\" Â Loaded {len(keypoints_sequence)} frames from {json_path.name}\")\n",
    "        return keypoints_sequence\n",
    "        \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error loading from {json_dir}: {e}\")\n",
    "        return None\n",
    "\n",
    "# --- 2. ê°ë„ ì¶”ì¶œ ë° ì‹œê°í™” í•¨ìˆ˜ ---\n",
    "\n",
    "# Keypoint ì¸ë±ìŠ¤ ë§¤í•‘ (p1, p2, p3)\n",
    "ANGLE_DEFINITIONS = {\n",
    "    \"L_Elbow(5-7-9)\":     (5, 7, 9),      # Shoulder - Elbow - Wrist\n",
    "    \"R_Elbow(6-8-10)\":    (6, 8, 10),     # Shoulder - Elbow - Wrist\n",
    "    \"L_Shoulder(7-5-11)\": (7, 5, 11),     # Elbow - Shoulder - Hip\n",
    "    \"R_Shoulder(8-6-12)\": (8, 6, 12),     # Elbow - Shoulder - Hip\n",
    "    \"L_Hip_Joint(5-11-13)\": (5, 11, 13),  # Shoulder - Hip - Knee (ë¬´ë¦ êµ´ê³¡/ì‹ ì „ ê°ë„)\n",
    "    \"R_Hip_Joint(6-12-14)\": (6, 12, 14),  # Shoulder - Hip - Knee\n",
    "    \"L_Knee(11-13-15)\":   (11, 13, 15),   # Hip - Knee - Ankle\n",
    "    \"R_Knee(12-14-16)\":   (12, 14, 16),   # Hip - Knee - Ankle\n",
    "}\n",
    "\n",
    "\n",
    "def plot_angle_trajectories(keypoints_sequence, sample_name):\n",
    "    \"\"\"\n",
    "    8ê°€ì§€ ì£¼ìš” ê´€ì ˆ ê°ë„ì˜ ë³€í™”ë¥¼ ì‹œê°„ì— ë”°ë¼ ì¶”ì í•˜ì—¬ ì‹œê°í™”í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    if not keypoints_sequence or not keypoints_sequence[0]:\n",
    "        logging.warning(f\"Cannot plot: keypoints sequence is empty or invalid for {sample_name}\")\n",
    "        return\n",
    "\n",
    "    first_valid_frame = next((frame for frame in keypoints_sequence if frame and 'instance_info' in frame and len(frame['instance_info']) > 0), None)\n",
    "    if not first_valid_frame or 'keypoints' not in first_valid_frame['instance_info'][0]:\n",
    "        logging.warning(f\"No valid keypoint data found in 'instance_info' for {sample_name}.\")\n",
    "        return\n",
    "\n",
    "    num_frames = len(keypoints_sequence)\n",
    "    # ê°ë„ ë°ì´í„°ë¥¼ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬ ì´ˆê¸°í™”\n",
    "    angle_trajectories = {name: [] for name in ANGLE_DEFINITIONS.keys()}\n",
    "    \n",
    "    # 2-1. í”„ë ˆì„ë³„ ê°ë„ ê³„ì‚°\n",
    "    for frame_data in keypoints_sequence:\n",
    "        keypoints_array = None\n",
    "        current_kps = {} # {index: [x, y]}\n",
    "        \n",
    "        if (frame_data and 'instance_info' in frame_data and \n",
    "            len(frame_data['instance_info']) > 0 and \n",
    "            'keypoints' in frame_data['instance_info'][0]):\n",
    "            \n",
    "            keypoints_list = frame_data['instance_info'][0]['keypoints']\n",
    "            keypoints_array = np.array(keypoints_list)\n",
    "            \n",
    "            # Keypointë¥¼ {index: [x, y]} í˜•íƒœë¡œ ì €ì¥\n",
    "            for idx in range(len(keypoints_array)):\n",
    "                # Keypoint ì¢Œí‘œëŠ” (x, y)ì´ê³ , ì„¸ ë²ˆì§¸ ìš”ì†ŒëŠ” ì‹ ë¢°ë„ì…ë‹ˆë‹¤.\n",
    "                current_kps[idx] = keypoints_array[idx, :2] \n",
    "\n",
    "        # 8ê°€ì§€ ê°ë„ì— ëŒ€í•´ ê³„ì‚° ë° ì €ì¥\n",
    "        for angle_name, (p1_idx, p2_idx, p3_idx) in ANGLE_DEFINITIONS.items():\n",
    "            \n",
    "            # ëª¨ë“  ì ì´ Keypoint ëª©ë¡ì— ìˆì–´ì•¼ ê³„ì‚°ì„ ì‹œë„í•©ë‹ˆë‹¤.\n",
    "            if keypoints_array is not None and all(idx in current_kps for idx in (p1_idx, p2_idx, p3_idx)):\n",
    "                p1 = current_kps[p1_idx]\n",
    "                p2 = current_kps[p2_idx] # ì¤‘ì‹¬ì \n",
    "                p3 = current_kps[p3_idx]\n",
    "                \n",
    "                angle = calculate_angle(p1, p2, p3)\n",
    "                angle_trajectories[angle_name].append(angle)\n",
    "            else:\n",
    "                angle_trajectories[angle_name].append(np.nan)\n",
    "\n",
    "    # 2-2. ì‹œê°í™”\n",
    "    frames = np.arange(num_frames)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(18, 8))\n",
    "    ax.set_title(f\"Joint Angle Trajectories over Time (Sample: {sample_name})\", fontsize=16)\n",
    "    \n",
    "    # ê° ê°ë„ ë³€í™” í”Œë¡¯\n",
    "    for angle_name, angles in angle_trajectories.items():\n",
    "        # ë°”ì´ì…‰ìŠ¤ ì»¬ì´ë¯€ë¡œ íŒ”ê¿ˆì¹˜ ê°ë„ë¥¼ ê°•ì¡°\n",
    "        linewidth = 2.5 if 'Elbow' in angle_name else 1.5\n",
    "        ax.plot(frames, angles, label=angle_name, linewidth=linewidth, alpha=0.8)\n",
    "        \n",
    "    ax.set_xlabel(\"Frame Number\")\n",
    "    ax.set_ylabel(\"Joint Angle (Degrees)\")\n",
    "    ax.set_ylim(0, 180) # ê°ë„ëŠ” 0ë„ì—ì„œ 180ë„ ì‚¬ì´\n",
    "    \n",
    "    ax.legend(loc='center left', bbox_to_anchor=(1.0, 0.5), ncol=1, fontsize=10) \n",
    "    ax.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# --- 3. ë°ì´í„°í”„ë ˆì„ ìˆœíšŒ ë° í”Œë¡¯ ì‹¤í–‰ (ê²½ë¡œ ê¸°ë°˜ í•„í„°ë§) ---\n",
    "\n",
    "TARGET_ACTIVITY_NAME = 'frontal__biceps_curl' \n",
    "TARGET_ACTIVITY_PATH_PATTERN = f'/{TARGET_ACTIVITY_NAME}'\n",
    "\n",
    "# ê²½ë¡œ ê¸°ë°˜ í•„í„°ë§\n",
    "target_df = train_df[train_df['interp_json_path'].str.contains(TARGET_ACTIVITY_PATH_PATTERN, case=False, na=False)].copy()\n",
    "\n",
    "logging.info(\"-\" * 50)\n",
    "logging.info(f\"Plotting Angle Trajectories for activity: {TARGET_ACTIVITY_NAME} (Found {len(target_df)} samples)\")\n",
    "\n",
    "NUM_SAMPLES_TO_PLOT = 1 \n",
    "\n",
    "if len(target_df) == 0:\n",
    "    logging.warning(f\"No samples found for activity: {TARGET_ACTIVITY_NAME}\")\n",
    "else:\n",
    "    for idx, row in target_df.head(NUM_SAMPLES_TO_PLOT).iterrows():\n",
    "        json_dir = row['interp_json_path']\n",
    "        sample_name = Path(json_dir).name\n",
    "        \n",
    "        logging.info(f\"Analyzing sample: {sample_name}...\")\n",
    "        \n",
    "        keypoints_sequence = load_keypoints_from_directory(json_dir)\n",
    "        \n",
    "        # ğŸš¨ ê°ë„ ì¶”ì  í”Œë¡¯ í•¨ìˆ˜ í˜¸ì¶œ\n",
    "        plot_angle_trajectories(keypoints_sequence, sample_name)\n",
    "\n",
    "logging.info(\"-\" * 50)\n",
    "logging.info(\"Trajectory analysis complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4957f83",
   "metadata": {},
   "source": [
    "# repetition counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11c7536f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - Total training samples: 83\n",
      "INFO - \n",
      "============================================================\n",
      "INFO - Testing Generalized Repetition Counter\n",
      "INFO - Activity: frontal__biceps_curl\n",
      "INFO - Found 3 samples\n",
      "INFO - ============================================================\n",
      "WARNING - No JSON files found in: /workspace/nas203/ds_RehabilitationMedicineData/IDs/Kimjihoo/3_project_HCCmove/data/4_INTERP_DATA/AI_dataset/N01/N01_Treatment/frontal__biceps_curl\n",
      "WARNING - No JSON files found in: /workspace/nas203/ds_RehabilitationMedicineData/IDs/Kimjihoo/3_project_HCCmove/data/4_INTERP_DATA/AI_dataset/N01/N01_Ward/frontal__biceps_curl\n",
      "WARNING - No JSON files found in: /workspace/nas203/ds_RehabilitationMedicineData/IDs/Kimjihoo/3_project_HCCmove/data/4_INTERP_DATA/AI_dataset/N01/N01_Ward/frontal__biceps_curlbilateral\n",
      "INFO - \n",
      "============================================================\n",
      "INFO - Analyzing: frontal__biceps_curlbilateral\n",
      "INFO - ============================================================\n",
      "ERROR - No valid trajectories found!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import logging\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.ndimage import uniform_filter1d\n",
    "\n",
    "# ë¡œê¹… ì„¤ì •\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s - %(message)s')\n",
    "\n",
    "# --- 1. ë©”íƒ€ë°ì´í„° ë¡œë“œ ë° JSON ë¡œë“œ í•¨ìˆ˜ ---\n",
    "\n",
    "df = pd.read_csv(\"/workspace/nas203/ds_RehabilitationMedicineData/IDs/tojihoo/ASAN_01_Repeatition_Counter/data/metadata.csv\")\n",
    "train_df = df[df['is_train'] == True].copy()\n",
    "logging.info(f\"Total training samples: {len(train_df)}\")\n",
    "\n",
    "def load_keypoints_from_directory(json_dir):\n",
    "    \"\"\"JSON ë””ë ‰í† ë¦¬ì—ì„œ í‚¤í¬ì¸íŠ¸ ì‹œí€€ìŠ¤ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.\"\"\"\n",
    "    try:\n",
    "        json_path = Path(json_dir)\n",
    "        json_files = sorted([f for f in json_path.glob('*.json')])\n",
    "        if len(json_files) == 0:\n",
    "            logging.warning(f\"No JSON files found in: {json_dir}\")\n",
    "            return None\n",
    "        \n",
    "        keypoints_sequence = []\n",
    "        for json_file in json_files:\n",
    "            try:\n",
    "                with open(json_file, 'r') as f:\n",
    "                    frame_data = json.load(f)\n",
    "                keypoints_sequence.append(frame_data)\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error loading {json_file}: {e}\")\n",
    "                keypoints_sequence.append(None)\n",
    "        \n",
    "        logging.info(f\"  Loaded {len(keypoints_sequence)} frames from {json_path.name}\")\n",
    "        return keypoints_sequence\n",
    "        \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error loading from {json_dir}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# --- 2. ë‹¨ê³„ 1: ìš´ë™ë³„ í•µì‹¬ ê´€ì ˆ ìë™ ì„ íƒ (ë¶„ì‚° ê¸°ë°˜) ---\n",
    "def extract_all_trajectories(keypoints_sequence, exclude_indices=None):\n",
    "    \"\"\"\n",
    "    ëª¨ë“  Keypointì˜ X, Y ì¢Œí‘œ ê¶¤ì ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.\n",
    "    \n",
    "    Returns:\n",
    "        dict: {keypoint_index: {'x': [...], 'y': [...], 'keypoint_name': str}}\n",
    "    \"\"\"\n",
    "    if not keypoints_sequence or not keypoints_sequence[0]:\n",
    "        return {}\n",
    "    \n",
    "    first_valid_frame = next((frame for frame in keypoints_sequence \n",
    "                             if frame and 'instance_info' in frame \n",
    "                             and len(frame['instance_info']) > 0), None)\n",
    "    \n",
    "    if not first_valid_frame:\n",
    "        return {}\n",
    "    \n",
    "    num_keypoints = first_valid_frame['meta_info']['num_keypoints']\n",
    "    keypoint_id2name = first_valid_frame['meta_info']['keypoint_id2name']\n",
    "    \n",
    "    if exclude_indices is None:\n",
    "        exclude_indices = set(range(5))  # ê¸°ë³¸ì ìœ¼ë¡œ 0~4ë²ˆ ì œì™¸\n",
    "    \n",
    "    trajectories = {}\n",
    "    for i in range(num_keypoints):\n",
    "        if i not in exclude_indices:\n",
    "            trajectories[i] = {\n",
    "                'x': [],\n",
    "                'y': [],\n",
    "                'keypoint_name': keypoint_id2name.get(str(i), f\"KP_{i}\")\n",
    "            }\n",
    "    \n",
    "    # í”„ë ˆì„ë³„ ì¢Œí‘œ ì¶”ì¶œ\n",
    "    for frame_data in keypoints_sequence:\n",
    "        keypoints_array = None\n",
    "        if (frame_data and 'instance_info' in frame_data and \n",
    "            len(frame_data['instance_info']) > 0 and \n",
    "            'keypoints' in frame_data['instance_info'][0]):\n",
    "            \n",
    "            keypoints_list = frame_data['instance_info'][0]['keypoints']\n",
    "            keypoints_array = np.array(keypoints_list)\n",
    "        \n",
    "        for index in trajectories.keys():\n",
    "            if keypoints_array is not None and index < len(keypoints_array) and keypoints_array.ndim >= 2:\n",
    "                trajectories[index]['x'].append(keypoints_array[index, 0])\n",
    "                trajectories[index]['y'].append(keypoints_array[index, 1])\n",
    "            else:\n",
    "                trajectories[index]['x'].append(np.nan)\n",
    "                trajectories[index]['y'].append(np.nan)\n",
    "    \n",
    "    return trajectories\n",
    "\n",
    "\n",
    "def calculate_keypoint_variance(trajectories):\n",
    "    \"\"\"\n",
    "    ê° Keypointì˜ X, Y ê¶¤ì ì— ëŒ€í•œ ë¶„ì‚°ì„ ê³„ì‚°í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    Returns:\n",
    "        dict: {keypoint_index: variance_value}\n",
    "    \"\"\"\n",
    "    variances = {}\n",
    "    \n",
    "    for kp_idx, data in trajectories.items():\n",
    "        x_arr = np.array(data['x'])\n",
    "        y_arr = np.array(data['y'])\n",
    "        \n",
    "        # NaN ì œê±°\n",
    "        x_valid = x_arr[~np.isnan(x_arr)]\n",
    "        y_valid = y_arr[~np.isnan(y_arr)]\n",
    "        \n",
    "        if len(x_valid) > 0 and len(y_valid) > 0:\n",
    "            var_x = np.var(x_valid)\n",
    "            var_y = np.var(y_valid)\n",
    "            variances[kp_idx] = var_x + var_y\n",
    "        else:\n",
    "            variances[kp_idx] = 0.0\n",
    "    \n",
    "    return variances\n",
    "\n",
    "\n",
    "def select_core_joint(variances, trajectories, top_k=3):\n",
    "    \"\"\"\n",
    "    ë¶„ì‚°ì´ ê°€ì¥ í° Keypointë“¤ì„ í•µì‹¬ ê´€ì ˆë¡œ ì„ íƒí•©ë‹ˆë‹¤.\n",
    "    \n",
    "    Returns:\n",
    "        list: [(keypoint_index, variance, keypoint_name), ...]\n",
    "    \"\"\"\n",
    "    sorted_kps = sorted(variances.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    core_joints = []\n",
    "    for kp_idx, var_value in sorted_kps[:top_k]:\n",
    "        kp_name = trajectories[kp_idx]['keypoint_name']\n",
    "        core_joints.append((kp_idx, var_value, kp_name))\n",
    "    \n",
    "    return core_joints\n",
    "\n",
    "\n",
    "# --- 3. ë‹¨ê³„ 2: ê´€ì ˆ ê°ë„ ê³„ì‚° í•¨ìˆ˜ ---\n",
    "\n",
    "def calculate_angle(p1, p2, p3):\n",
    "    \"\"\"\n",
    "    ì„¸ ì ìœ¼ë¡œ ì´ë£¨ì–´ì§„ ê°ë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤ (p2ê°€ ê¼­ì§€ì ).\n",
    "    \n",
    "    Returns:\n",
    "        float: ê°ë„ (degree)\n",
    "    \"\"\"\n",
    "    v1 = np.array([p1[0] - p2[0], p1[1] - p2[1]])\n",
    "    v2 = np.array([p3[0] - p2[0], p3[1] - p2[1]])\n",
    "    \n",
    "    cos_angle = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2) + 1e-8)\n",
    "    cos_angle = np.clip(cos_angle, -1.0, 1.0)\n",
    "    angle = np.arccos(cos_angle)\n",
    "    \n",
    "    return np.degrees(angle)\n",
    "\n",
    "\n",
    "def extract_joint_angles(keypoints_sequence, joint_config):\n",
    "    \"\"\"\n",
    "    íŠ¹ì • ê´€ì ˆì˜ ê°ë„ ì‹œê³„ì—´ì„ ê³„ì‚°í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    Args:\n",
    "        joint_config: dict with 'joint_idx', 'parent_idx', 'child_idx'\n",
    "    \n",
    "    Returns:\n",
    "        np.array: ê°ë„ ì‹œê³„ì—´\n",
    "    \"\"\"\n",
    "    angles = []\n",
    "    \n",
    "    for frame_data in keypoints_sequence:\n",
    "        if (frame_data and 'instance_info' in frame_data and \n",
    "            len(frame_data['instance_info']) > 0 and \n",
    "            'keypoints' in frame_data['instance_info'][0]):\n",
    "            \n",
    "            keypoints_array = np.array(frame_data['instance_info'][0]['keypoints'])\n",
    "            \n",
    "            try:\n",
    "                p_parent = keypoints_array[joint_config['parent_idx']][:2]\n",
    "                p_joint = keypoints_array[joint_config['joint_idx']][:2]\n",
    "                p_child = keypoints_array[joint_config['child_idx']][:2]\n",
    "                \n",
    "                angle = calculate_angle(p_parent, p_joint, p_child)\n",
    "                angles.append(angle)\n",
    "            except:\n",
    "                angles.append(np.nan)\n",
    "        else:\n",
    "            angles.append(np.nan)\n",
    "    \n",
    "    return np.array(angles)\n",
    "\n",
    "\n",
    "# --- 4. ë‹¨ê³„ 3: Peak/Valley íƒì§€ ë° í•„í„°ë§ ---\n",
    "\n",
    "def smooth_signal(signal, window_size=5):\n",
    "    \"\"\"ì´ë™ í‰ê·  í•„í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹ í˜¸ë¥¼ ìŠ¤ë¬´ë”©í•©ë‹ˆë‹¤.\"\"\"\n",
    "    valid_mask = ~np.isnan(signal)\n",
    "    smoothed = signal.copy()\n",
    "    \n",
    "    if np.sum(valid_mask) > window_size:\n",
    "        smoothed[valid_mask] = uniform_filter1d(signal[valid_mask], size=window_size, mode='nearest')\n",
    "    \n",
    "    return smoothed\n",
    "\n",
    "\n",
    "def detect_peaks_valleys(signal, prominence_ratio=0.15, distance=10):\n",
    "    \"\"\"\n",
    "    Peakì™€ Valleyë¥¼ íƒì§€í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    Args:\n",
    "        prominence_ratio: ì‹ í˜¸ ë²”ìœ„ì˜ ëª‡ %ë¥¼ prominenceë¡œ ì‚¬ìš©í• ì§€ (0.15 = 15%)\n",
    "        distance: Peak ê°„ ìµœì†Œ ê±°ë¦¬ (í”„ë ˆì„ ë‹¨ìœ„)\n",
    "    \n",
    "    Returns:\n",
    "        peaks, valleys: Peakì™€ Valleyì˜ ì¸ë±ìŠ¤ ë°°ì—´\n",
    "    \"\"\"\n",
    "    valid_mask = ~np.isnan(signal)\n",
    "    valid_signal = signal[valid_mask]\n",
    "    \n",
    "    if len(valid_signal) < 10:\n",
    "        return np.array([]), np.array([])\n",
    "    \n",
    "    # ì‹ í˜¸ ë²”ìœ„ ê¸°ë°˜ prominence ê³„ì‚°\n",
    "    signal_range = np.max(valid_signal) - np.min(valid_signal)\n",
    "    prominence = signal_range * prominence_ratio\n",
    "    \n",
    "    # Peak íƒì§€\n",
    "    peaks, _ = find_peaks(valid_signal, prominence=prominence, distance=distance)\n",
    "    \n",
    "    # Valley íƒì§€ (ì‹ í˜¸ ë°˜ì „)\n",
    "    valleys, _ = find_peaks(-valid_signal, prominence=prominence, distance=distance)\n",
    "    \n",
    "    # ì›ë˜ ì¸ë±ìŠ¤ë¡œ ë§¤í•‘\n",
    "    valid_indices = np.where(valid_mask)[0]\n",
    "    peaks = valid_indices[peaks]\n",
    "    valleys = valid_indices[valleys]\n",
    "    \n",
    "    return peaks, valleys\n",
    "\n",
    "\n",
    "# --- 5. ë‹¨ê³„ 4: ë°˜ë³µ íšŸìˆ˜ ê³„ì‚° ---\n",
    "\n",
    "def count_repetitions(peaks, valleys):\n",
    "    \"\"\"\n",
    "    Peakì™€ Valleyì˜ êµì°¨ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë°˜ë³µ íšŸìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    Returns:\n",
    "        int: ë°˜ë³µ íšŸìˆ˜\n",
    "    \"\"\"\n",
    "    if len(peaks) == 0 or len(valleys) == 0:\n",
    "        return 0\n",
    "    \n",
    "    # Peakì™€ Valleyë¥¼ ì‹œê°„ ìˆœì„œëŒ€ë¡œ ë³‘í•©\n",
    "    events = []\n",
    "    for p in peaks:\n",
    "        events.append((p, 'peak'))\n",
    "    for v in valleys:\n",
    "        events.append((v, 'valley'))\n",
    "    \n",
    "    events.sort(key=lambda x: x[0])\n",
    "    \n",
    "    # êµì°¨ íŒ¨í„´ íƒì§€\n",
    "    rep_count = 0\n",
    "    last_event = None\n",
    "    \n",
    "    for idx, event_type in events:\n",
    "        if last_event is not None and last_event != event_type:\n",
    "            rep_count += 1\n",
    "        last_event = event_type\n",
    "    \n",
    "    # í•œ ë²ˆì˜ êµì°¨ëŠ” ë°˜ë³µì˜ ì ˆë°˜ì´ë¯€ë¡œ 2ë¡œ ë‚˜ëˆ”\n",
    "    return rep_count // 2\n",
    "\n",
    "\n",
    "# --- 6. í†µí•© í•¨ìˆ˜: ì¼ë°˜í™”ëœ Repetition Counter ---\n",
    "\n",
    "def generalized_repetition_counter(keypoints_sequence, sample_name, \n",
    "                                   use_angle=True, \n",
    "                                   prominence_ratio=0.15,\n",
    "                                   window_size=5,\n",
    "                                   visualize=True):\n",
    "    \"\"\"\n",
    "    ì¼ë°˜í™”ëœ ë°˜ë³µ íšŸìˆ˜ ì¹´ìš´í„°.\n",
    "    \n",
    "    Args:\n",
    "        keypoints_sequence: í‚¤í¬ì¸íŠ¸ ì‹œí€€ìŠ¤\n",
    "        sample_name: ìƒ˜í”Œ ì´ë¦„\n",
    "        use_angle: Trueë©´ ê´€ì ˆ ê°ë„ ì‚¬ìš©, Falseë©´ Y ì¢Œí‘œ ì‚¬ìš©\n",
    "        prominence_ratio: Peak íƒì§€ ë¯¼ê°ë„ (0.1~0.2 ê¶Œì¥)\n",
    "        window_size: ìŠ¤ë¬´ë”© ìœˆë„ìš° í¬ê¸°\n",
    "        visualize: ì‹œê°í™” ì—¬ë¶€\n",
    "    \n",
    "    Returns:\n",
    "        dict: ê²°ê³¼ ì •ë³´\n",
    "    \"\"\"\n",
    "    logging.info(f\"\\n{'='*60}\")\n",
    "    logging.info(f\"Analyzing: {sample_name}\")\n",
    "    logging.info(f\"{'='*60}\")\n",
    "    \n",
    "    # ë‹¨ê³„ 1: ëª¨ë“  Keypoint ê¶¤ì  ì¶”ì¶œ ë° ë¶„ì‚° ê³„ì‚°\n",
    "    trajectories = extract_all_trajectories(keypoints_sequence)\n",
    "    if not trajectories:\n",
    "        logging.error(\"No valid trajectories found!\")\n",
    "        return None\n",
    "    \n",
    "    variances = calculate_keypoint_variance(trajectories)\n",
    "    core_joints = select_core_joint(variances, trajectories, top_k=5)\n",
    "    \n",
    "    logging.info(\"\\n[Step 1] Top 5 Core Joints (Highest Variance):\")\n",
    "    for rank, (kp_idx, var_val, kp_name) in enumerate(core_joints, 1):\n",
    "        logging.info(f\"  {rank}. {kp_name} (KP {kp_idx}): Variance = {var_val:.2f}\")\n",
    "    \n",
    "    # ê°€ì¥ ë¶„ì‚°ì´ í° ê´€ì ˆ ì„ íƒ\n",
    "    primary_joint_idx, _, primary_joint_name = core_joints[0]\n",
    "    logging.info(f\"\\n[Step 2] Selected Primary Joint: {primary_joint_name} (KP {primary_joint_idx})\")\n",
    "    \n",
    "    # ë‹¨ê³„ 2: ì‹ í˜¸ ì¶”ì¶œ (ê°ë„ ë˜ëŠ” ì¢Œí‘œ)\n",
    "    if use_angle:\n",
    "        # ê´€ì ˆ ê°ë„ ê³„ì‚°ì„ ìœ„í•œ ì„¤ì • (ì˜ˆì‹œ: íŒ”ê¿ˆì¹˜, ë¬´ë¦ ë“±)\n",
    "        # ì‹¤ì œë¡œëŠ” ê´€ì ˆ íƒ€ì…ì— ë”°ë¼ parent, childë¥¼ ë™ì ìœ¼ë¡œ ê²°ì •í•´ì•¼ í•¨\n",
    "        # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨íˆ ì¸ì ‘ ê´€ì ˆì„ ì‚¬ìš©\n",
    "        joint_config = {\n",
    "            'joint_idx': primary_joint_idx,\n",
    "            'parent_idx': max(5, primary_joint_idx - 2),\n",
    "            'child_idx': min(16, primary_joint_idx + 2)\n",
    "        }\n",
    "        signal = extract_joint_angles(keypoints_sequence, joint_config)\n",
    "        signal_name = \"Joint Angle\"\n",
    "    else:\n",
    "        # Y ì¢Œí‘œ ì‚¬ìš©\n",
    "        signal = np.array(trajectories[primary_joint_idx]['y'])\n",
    "        signal_name = \"Y Coordinate\"\n",
    "    \n",
    "    logging.info(f\"  Tracking: {signal_name}\")\n",
    "    \n",
    "    # ë‹¨ê³„ 3: ìŠ¤ë¬´ë”© ë° Peak/Valley íƒì§€\n",
    "    smoothed_signal = smooth_signal(signal, window_size=window_size)\n",
    "    peaks, valleys = detect_peaks_valleys(smoothed_signal, \n",
    "                                         prominence_ratio=prominence_ratio,\n",
    "                                         distance=10)\n",
    "    \n",
    "    logging.info(f\"\\n[Step 3] Peak/Valley Detection:\")\n",
    "    logging.info(f\"  Found {len(peaks)} peaks and {len(valleys)} valleys\")\n",
    "    \n",
    "    # ë‹¨ê³„ 4: ë°˜ë³µ íšŸìˆ˜ ê³„ì‚°\n",
    "    rep_count = count_repetitions(peaks, valleys)\n",
    "    logging.info(f\"\\n[Step 4] Repetition Count: {rep_count}\")\n",
    "    \n",
    "    # ì‹œê°í™”\n",
    "    if visualize:\n",
    "        fig, axes = plt.subplots(2, 1, figsize=(14, 10))\n",
    "        \n",
    "        # ìƒë‹¨: 2D ê¶¤ì \n",
    "        ax1 = axes[0]\n",
    "        ax1.plot(trajectories[primary_joint_idx]['x'], \n",
    "                trajectories[primary_joint_idx]['y'], \n",
    "                'b-', linewidth=2, label=primary_joint_name)\n",
    "        ax1.set_xlabel(\"X Coordinate\")\n",
    "        ax1.set_ylabel(\"Y Coordinate\")\n",
    "        ax1.set_title(f\"2D Trajectory: {primary_joint_name}\")\n",
    "        ax1.invert_yaxis()\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        ax1.legend()\n",
    "        ax1.set_aspect('equal', adjustable='box')\n",
    "        \n",
    "        # í•˜ë‹¨: ì‹œê³„ì—´ ì‹ í˜¸ + Peak/Valley\n",
    "        ax2 = axes[1]\n",
    "        frames = np.arange(len(signal))\n",
    "        ax2.plot(frames, signal, 'b-', alpha=0.3, label='Original', linewidth=1)\n",
    "        ax2.plot(frames, smoothed_signal, 'b-', label='Smoothed', linewidth=2)\n",
    "        ax2.plot(peaks, smoothed_signal[peaks], 'ro', markersize=10, label='Peaks')\n",
    "        ax2.plot(valleys, smoothed_signal[valleys], 'go', markersize=10, label='Valleys')\n",
    "        \n",
    "        ax2.set_xlabel(\"Frame\")\n",
    "        ax2.set_ylabel(signal_name)\n",
    "        ax2.set_title(f\"{signal_name} vs Time | Repetitions: {rep_count}\")\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        ax2.legend()\n",
    "        \n",
    "        plt.suptitle(f\"Generalized Repetition Counter\\nSample: {sample_name}\", \n",
    "                    fontsize=14, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    result = {\n",
    "        'sample_name': sample_name,\n",
    "        'primary_joint': primary_joint_name,\n",
    "        'primary_joint_idx': primary_joint_idx,\n",
    "        'variance': variances[primary_joint_idx],\n",
    "        'num_peaks': len(peaks),\n",
    "        'num_valleys': len(valleys),\n",
    "        'repetition_count': rep_count,\n",
    "        'signal_type': signal_name\n",
    "    }\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "# --- 7. ì‹¤í–‰ ë° í…ŒìŠ¤íŠ¸ ---\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # í…ŒìŠ¤íŠ¸í•  ìš´ë™ ì„ íƒ\n",
    "    TARGET_ACTIVITY_NAME = 'frontal__biceps_curl'  # ë˜ëŠ” ë‹¤ë¥¸ ìš´ë™ìœ¼ë¡œ ë³€ê²½ ê°€ëŠ¥\n",
    "    TARGET_ACTIVITY_PATH_PATTERN = f'/{TARGET_ACTIVITY_NAME}'\n",
    "    \n",
    "    # ê²½ë¡œ ê¸°ë°˜ í•„í„°ë§\n",
    "    target_df = train_df[train_df['interp_json_path'].str.contains(\n",
    "        TARGET_ACTIVITY_PATH_PATTERN, case=False, na=False)].copy()\n",
    "    \n",
    "    logging.info(f\"\\n{'='*60}\")\n",
    "    logging.info(f\"Testing Generalized Repetition Counter\")\n",
    "    logging.info(f\"Activity: {TARGET_ACTIVITY_NAME}\")\n",
    "    logging.info(f\"Found {len(target_df)} samples\")\n",
    "    logging.info(f\"{'='*60}\")\n",
    "    \n",
    "    NUM_SAMPLES_TO_TEST = 3  # í…ŒìŠ¤íŠ¸í•  ìƒ˜í”Œ ìˆ˜\n",
    "    \n",
    "    if len(target_df) == 0:\n",
    "        logging.warning(f\"No samples found for activity: {TARGET_ACTIVITY_NAME}\")\n",
    "    else:\n",
    "        results = []\n",
    "        \n",
    "        for idx, row in target_df.head(NUM_SAMPLES_TO_TEST).iterrows():\n",
    "            json_dir = row['interp_json_path']\n",
    "            sample_name = Path(json_dir).name\n",
    "            \n",
    "            keypoints_sequence = load_keypoints_from_directory(json_dir)\n",
    "            \n",
    "            if keypoints_sequence:\n",
    "                result = generalized_repetition_counter(\n",
    "                    keypoints_sequence, \n",
    "                    sample_name,\n",
    "                    use_angle=False,  # Y ì¢Œí‘œ ì‚¬ìš© (ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸)\n",
    "                    prominence_ratio=0.15,\n",
    "                    window_size=7,\n",
    "                    visualize=True\n",
    "                )\n",
    "                \n",
    "                if result:\n",
    "                    results.append(result)\n",
    "        \n",
    "        # ê²°ê³¼ ìš”ì•½\n",
    "        if results:\n",
    "            logging.info(f\"\\n{'='*60}\")\n",
    "            logging.info(\"SUMMARY\")\n",
    "            logging.info(f\"{'='*60}\")\n",
    "            for r in results:\n",
    "                logging.info(f\"\\nSample: {r['sample_name']}\")\n",
    "                logging.info(f\"  Primary Joint: {r['primary_joint']} (KP {r['primary_joint_idx']})\")\n",
    "                logging.info(f\"  Variance: {r['variance']:.2f}\")\n",
    "                logging.info(f\"  Peaks/Valleys: {r['num_peaks']}/{r['num_valleys']}\")\n",
    "                logging.info(f\"  Repetition Count: {r['repetition_count']}\")\n",
    "\n",
    "# ì›í•˜ëŠ” ìš´ë™ìœ¼ë¡œ ë³€ê²½ ê°€ëŠ¥\n",
    "TARGET_ACTIVITY_NAME = 'frontal__biceps_curl'\n",
    "\n",
    "# íŒŒë¼ë¯¸í„° ì¡°ì • ê°€ëŠ¥\n",
    "result = generalized_repetition_counter(\n",
    "    keypoints_sequence, \n",
    "    sample_name,\n",
    "    use_angle=False,      # True: ê´€ì ˆ ê°ë„, False: Y ì¢Œí‘œ\n",
    "    prominence_ratio=0.15, # 0.1~0.2 ê¶Œì¥ (ë¯¼ê°ë„ ì¡°ì ˆ)\n",
    "    window_size=7,        # ìŠ¤ë¬´ë”© ê°•ë„\n",
    "    visualize=True        # ì‹œê°í™” ì—¬ë¶€\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d72c833",
   "metadata": {},
   "source": [
    "## threshold ë°©ì‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1798785",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - Total training samples: 83\n",
      "INFO - --------------------------------------------------\n",
      "INFO - Plotting Threshold Counter for activity: frontal__biceps_curl (Found 3 samples)\n",
      "INFO - Analyzing sample: frontal__biceps_curl...\n",
      "INFO -  Â Loaded 0 frames from frontal__biceps_curl\n",
      "WARNING - Cannot count: keypoints sequence is empty or invalid for frontal__biceps_curl\n",
      "INFO - --------------------------------------------------\n",
      "INFO - Analysis complete.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import logging\n",
    "import math\n",
    "from scipy.ndimage import uniform_filter1d # ì´ë™ í‰ê·  í•„í„° ì‚¬ìš©ì„ ìœ„í•´ import\n",
    "\n",
    "# ë¡œê¹… ì„¤ì •\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s - %(message)s')\n",
    "\n",
    "# --- 0. ê°ë„ ê³„ì‚° ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ (ì´ì „ê³¼ ë™ì¼) ---\n",
    "\n",
    "def calculate_angle(p1, p2, p3):\n",
    "    # ... (ì´ì „ ì½”ë“œì˜ calculate_angle í•¨ìˆ˜ ë‚´ìš©) ...\n",
    "    try:\n",
    "        p1 = np.array(p1)\n",
    "        p2 = np.array(p2)\n",
    "        p3 = np.array(p3)\n",
    "        vec_a = p1 - p2\n",
    "        vec_c = p3 - p2\n",
    "        dot_product = np.dot(vec_a, vec_c)\n",
    "        norm_a = np.linalg.norm(vec_a)\n",
    "        norm_c = np.linalg.norm(vec_c)\n",
    "        \n",
    "        if norm_a == 0 or norm_c == 0:\n",
    "            return np.nan\n",
    "        \n",
    "        cosine_angle = dot_product / (norm_a * norm_c)\n",
    "        cosine_angle = np.clip(cosine_angle, -1.0, 1.0)\n",
    "        angle_deg = np.degrees(np.arccos(cosine_angle))\n",
    "        \n",
    "        return angle_deg\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "# Keypoint ì¸ë±ìŠ¤ ë§¤í•‘ (p1, p2, p3)\n",
    "# ë¶„ì„í•  ê°ë„ë§Œ ì •ì˜ (ë°”ì´ìŠ¤í…ìŠ¤ ì»¬ì˜ í•µì‹¬: íŒ”ê¿ˆì¹˜)\n",
    "ANGLE_DEFINITIONS = {\n",
    "    \"L_Elbow(5-7-9)\": (5, 7, 9),      # Shoulder - Elbow - Wrist\n",
    "    \"R_Elbow(6-8-10)\": (6, 8, 10),     # Shoulder - Elbow - Wrist\n",
    "}\n",
    "\n",
    "# --- 1. ë©”íƒ€ë°ì´í„° ë¡œë“œ ë° JSON ë¡œë“œ í•¨ìˆ˜ (ì´ì „ê³¼ ë™ì¼) ---\n",
    "\n",
    "df = pd.read_csv(\"/workspace/nas203/ds_RehabilitationMedicineData/IDs/tojihoo/ASAN_01_Repeatition_Counter/data/metadata.csv\")\n",
    "train_df = df[df['is_train'] == True].copy()\n",
    "logging.info(f\"Total training samples: {len(train_df)}\")\n",
    "\n",
    "def load_keypoints_from_directory(json_dir):\n",
    "    # ... (ì´ì „ ì½”ë“œì™€ ë™ì¼, ìƒëµ) ...\n",
    "    try:\n",
    "        json_path = Path(json_dir)\n",
    "        # ... (ì¤‘ëµ) ...\n",
    "        json_files = sorted([f for f in json_path.glob('*.json')])\n",
    "        # ... (ì¤‘ëµ) ...\n",
    "        \n",
    "        keypoints_sequence = []\n",
    "        for json_file in json_files:\n",
    "            try:\n",
    "                with open(json_file, 'r') as f:\n",
    "                    frame_data = json.load(f)\n",
    "                keypoints_sequence.append(frame_data)\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error loading {json_file}: {e}\")\n",
    "                keypoints_sequence.append(None)\n",
    "        \n",
    "        logging.info(f\" Â Loaded {len(keypoints_sequence)} frames from {json_path.name}\")\n",
    "        return keypoints_sequence\n",
    "        \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error loading from {json_dir}: {e}\")\n",
    "        return None\n",
    "\n",
    "# --- 2. Threshold ê¸°ë°˜ ì¹´ìš´íŒ… ë° ì‹œê°í™” í•¨ìˆ˜ ---\n",
    "\n",
    "def plot_and_count_with_threshold(keypoints_sequence, sample_name):\n",
    "    \n",
    "    # ... (ê°ë„ ì¶”ì¶œ ë¡œì§) ...\n",
    "    if not keypoints_sequence or not keypoints_sequence[0]:\n",
    "        logging.warning(f\"Cannot count: keypoints sequence is empty or invalid for {sample_name}\")\n",
    "        return\n",
    "\n",
    "    first_valid_frame = next((frame for frame in keypoints_sequence if frame and 'instance_info' in frame and len(frame['instance_info']) > 0), None)\n",
    "    if not first_valid_frame or 'keypoints' not in first_valid_frame['instance_info'][0]:\n",
    "        logging.warning(f\"No valid keypoint data found in 'instance_info' for {sample_name}.\")\n",
    "        return\n",
    "\n",
    "    num_frames = len(keypoints_sequence)\n",
    "    angle_trajectories = {name: [] for name in ANGLE_DEFINITIONS.keys()}\n",
    "    \n",
    "    # 2-1. í”„ë ˆì„ë³„ ê°ë„ ê³„ì‚° (ì´ì „ ì½”ë“œì™€ ë™ì¼)\n",
    "    for frame_data in keypoints_sequence:\n",
    "        keypoints_array = None\n",
    "        current_kps = {}\n",
    "        \n",
    "        if (frame_data and 'instance_info' in frame_data and \n",
    "            len(frame_data['instance_info']) > 0 and \n",
    "            'keypoints' in frame_data['instance_info'][0]):\n",
    "            \n",
    "            keypoints_list = frame_data['instance_info'][0]['keypoints']\n",
    "            keypoints_array = np.array(keypoints_list)\n",
    "            \n",
    "            for idx in range(len(keypoints_array)):\n",
    "                current_kps[idx] = keypoints_array[idx, :2] \n",
    "\n",
    "        for angle_name, (p1_idx, p2_idx, p3_idx) in ANGLE_DEFINITIONS.items():\n",
    "            if keypoints_array is not None and all(idx in current_kps for idx in (p1_idx, p2_idx, p3_idx)):\n",
    "                angle = calculate_angle(current_kps[p1_idx], current_kps[p2_idx], current_kps[p3_idx])\n",
    "                angle_trajectories[angle_name].append(angle)\n",
    "            else:\n",
    "                angle_trajectories[angle_name].append(np.nan)\n",
    "\n",
    "    # ğŸš¨ Left Elbow Angle (ì™¼ìª½ íŒ”ê¿ˆì¹˜ ê°ë„)ë§Œ ë¶„ì„ ëŒ€ìƒìœ¼ë¡œ ì„ íƒ\n",
    "    if 'L_Elbow(5-7-9)' not in angle_trajectories:\n",
    "        logging.warning(\"L_Elbow data not found in trajectories.\")\n",
    "        return\n",
    "        \n",
    "    raw_angles = np.array(angle_trajectories['L_Elbow(5-7-9)'])\n",
    "    \n",
    "    # 2-2. ë°ì´í„° ì „ì²˜ë¦¬ (Moving Average Filter)\n",
    "    # ìœˆë„ìš° í¬ê¸° ì„¤ì • (ì˜ˆ: 5 í”„ë ˆì„)\n",
    "    window_size = 5\n",
    "    smoothed_angles = uniform_filter1d(raw_angles, size=window_size, mode='nearest')\n",
    "    \n",
    "    # 2-3. Threshold ë° State Machine ì„¤ì •\n",
    "    \n",
    "    # ìš´ë™ì— ë§ê²Œ ì¡°ì • í•„ìš”: ë°”ì´ì…‰ìŠ¤ ì»¬ì€ 170ë„(í„)ì—ì„œ 30ë„(êµ½í˜) ì‚¬ì´ì˜ ê°’ì„ ê°€ì§‘ë‹ˆë‹¤.\n",
    "    UPPER_THRESHOLD = 150 # íŒ”ì„ í¸ ìƒíƒœ (DOWN) ì„ê³„ê°’\n",
    "    LOWER_THRESHOLD = 50  # íŒ”ì„ êµ½íŒ ìƒíƒœ (UP) ì„ê³„ê°’\n",
    "\n",
    "    # State ì •ì˜: 0=DOWN, 1=UP\n",
    "    current_state = 0 \n",
    "    rep_count = 0\n",
    "    \n",
    "    # ì¹´ìš´íŒ… ë¡œì§ì„ ì‹œê°í™”í•˜ê¸° ìœ„í•œ ì´ë²¤íŠ¸ ë¦¬ìŠ¤íŠ¸\n",
    "    count_events = [] \n",
    "\n",
    "    # 2-4. ë°˜ë³µ íšŸìˆ˜ ì¹´ìš´íŒ…\n",
    "    for frame_idx, angle in enumerate(smoothed_angles):\n",
    "        if np.isnan(angle):\n",
    "            continue\n",
    "\n",
    "        # ìƒíƒœ ì „í™˜ ì¡°ê±´ í™•ì¸\n",
    "        if current_state == 0: # í˜„ì¬ ìƒíƒœ: DOWN (íŒ”ì„ í¸ ìƒíƒœ)\n",
    "            if angle < LOWER_THRESHOLD:\n",
    "                # DOWN -> UP ì „í™˜ (íŒ” êµ½í˜ ì‹œì‘ -> ìˆ˜ì¶• ì™„ë£Œ)\n",
    "                current_state = 1\n",
    "                count_events.append((frame_idx, angle, 'UP'))\n",
    "                \n",
    "        elif current_state == 1: # í˜„ì¬ ìƒíƒœ: UP (íŒ”ì„ êµ½íŒ ìƒíƒœ)\n",
    "            if angle > UPPER_THRESHOLD:\n",
    "                # UP -> DOWN ì „í™˜ (ìˆ˜ì¶• ì™„ë£Œ -> ë³µê·€ ì™„ë£Œ)\n",
    "                rep_count += 1\n",
    "                current_state = 0\n",
    "                count_events.append((frame_idx, angle, 'DOWN'))\n",
    "\n",
    "    # 2-5. ì‹œê°í™”\n",
    "    frames = np.arange(num_frames)\n",
    "    fig, ax = plt.subplots(figsize=(18, 6))\n",
    "    \n",
    "    ax.set_title(f\"Threshold-based Repetition Counter for L_Elbow (Sample: {sample_name})\\nTotal Reps: {rep_count}\", fontsize=16)\n",
    "    \n",
    "    # ìŠ¤ë¬´ë”©ëœ ê°ë„ í”Œë¡¯\n",
    "    ax.plot(frames, smoothed_angles, label='Smoothed L_Elbow Angle', color='blue', linewidth=2)\n",
    "    \n",
    "    # Threshold ë¼ì¸\n",
    "    ax.axhline(UPPER_THRESHOLD, color='red', linestyle='--', label=f'Upper Threshold ({UPPER_THRESHOLD}Â°)')\n",
    "    ax.axhline(LOWER_THRESHOLD, color='green', linestyle='--', label=f'Lower Threshold ({LOWER_THRESHOLD}Â°)')\n",
    "    \n",
    "    # ì¹´ìš´íŒ… ì´ë²¤íŠ¸ í‘œì‹œ\n",
    "    for frame_idx, angle, state in count_events:\n",
    "        color = 'red' if state == 'DOWN' else 'green'\n",
    "        ax.plot(frame_idx, angle, 'o', color=color, markersize=8, markeredgecolor='black', alpha=0.8)\n",
    "    \n",
    "    ax.set_xlabel(\"Frame Number\")\n",
    "    ax.set_ylabel(\"Angle (Degrees)\")\n",
    "    ax.set_ylim(0, 180)\n",
    "    ax.legend(loc='upper right')\n",
    "    ax.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "    logging.info(f\"Final Repetition Count for {sample_name}: {rep_count}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# --- 3. ë°ì´í„°í”„ë ˆì„ ìˆœíšŒ ë° í”Œë¡¯ ì‹¤í–‰ (ê²½ë¡œ ê¸°ë°˜ í•„í„°ë§) ---\n",
    "\n",
    "TARGET_ACTIVITY_NAME = 'frontal__biceps_curl' \n",
    "TARGET_ACTIVITY_PATH_PATTERN = f'/{TARGET_ACTIVITY_NAME}'\n",
    "\n",
    "target_df = train_df[train_df['interp_json_path'].str.contains(TARGET_ACTIVITY_PATH_PATTERN, case=False, na=False)].copy()\n",
    "\n",
    "logging.info(\"-\" * 50)\n",
    "logging.info(f\"Plotting Threshold Counter for activity: {TARGET_ACTIVITY_NAME} (Found {len(target_df)} samples)\")\n",
    "\n",
    "NUM_SAMPLES_TO_PLOT = 1 \n",
    "\n",
    "if len(target_df) == 0:\n",
    "    logging.warning(f\"No samples found for activity: {TARGET_ACTIVITY_NAME}\")\n",
    "else:\n",
    "    for idx, row in target_df.head(NUM_SAMPLES_TO_PLOT).iterrows():\n",
    "        json_dir = row['interp_json_path']\n",
    "        sample_name = Path(json_dir).name\n",
    "        \n",
    "        logging.info(f\"Analyzing sample: {sample_name}...\")\n",
    "        \n",
    "        keypoints_sequence = load_keypoints_from_directory(json_dir)\n",
    "        \n",
    "        # ğŸš¨ Threshold ì¹´ìš´í„° í•¨ìˆ˜ í˜¸ì¶œ\n",
    "        plot_and_count_with_threshold(keypoints_sequence, sample_name)\n",
    "\n",
    "logging.info(\"-\" * 50)\n",
    "logging.info(\"Analysis complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1782c1b5",
   "metadata": {},
   "source": [
    "## ì†ë„ ê¸°ë°˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a37f73d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - Total training samples: 83\n",
      "INFO - --------------------------------------------------\n",
      "INFO - Plotting Derivative Counter for activity: frontal__biceps_curl (Found 3 samples)\n",
      "INFO - Analyzing sample: frontal__biceps_curl...\n",
      "INFO -  Â Loaded 0 frames from frontal__biceps_curl\n",
      "WARNING - Cannot count: keypoints sequence is empty or invalid for frontal__biceps_curl\n",
      "INFO - --------------------------------------------------\n",
      "INFO - Analysis complete.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import logging\n",
    "from scipy.ndimage import uniform_filter1d # ë…¸ì´ì¦ˆ ì œê±°ë¥¼ ìœ„í•œ í•„í„°\n",
    "\n",
    "# ë¡œê¹… ì„¤ì •\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s - %(message)s')\n",
    "\n",
    "# --- 0. ê°ë„ ê³„ì‚° ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ (ì´ì „ê³¼ ë™ì¼) ---\n",
    "\n",
    "def calculate_angle(p1, p2, p3):\n",
    "    \"\"\"ì„¸ ì  p1, p2(center), p3ì„ ì´ìš©í•´ ê°ë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.\"\"\"\n",
    "    try:\n",
    "        p1 = np.array(p1)\n",
    "        p2 = np.array(p2)\n",
    "        p3 = np.array(p3)\n",
    "        vec_a = p1 - p2\n",
    "        vec_c = p3 - p2\n",
    "        dot_product = np.dot(vec_a, vec_c)\n",
    "        norm_a = np.linalg.norm(vec_a)\n",
    "        norm_c = np.linalg.norm(vec_c)\n",
    "        \n",
    "        if norm_a == 0 or norm_c == 0:\n",
    "            return np.nan\n",
    "        \n",
    "        cosine_angle = np.clip(dot_product / (norm_a * norm_c), -1.0, 1.0)\n",
    "        angle_deg = np.degrees(np.arccos(cosine_angle))\n",
    "        \n",
    "        return angle_deg\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "# ë¶„ì„í•  íŒ”ê¿ˆì¹˜ ê°ë„ ì •ì˜\n",
    "ANGLE_DEFINITIONS = {\n",
    "    \"L_Elbow(5-7-9)\": (5, 7, 9),      # Shoulder - Elbow - Wrist\n",
    "}\n",
    "\n",
    "# --- 1. ë°ì´í„° ë¡œë“œ í•¨ìˆ˜ (ì´ì „ê³¼ ë™ì¼) ---\n",
    "\n",
    "df = pd.read_csv(\"/workspace/nas203/ds_RehabilitationMedicineData/IDs/tojihoo/ASAN_01_Repeatition_Counter/data/metadata.csv\")\n",
    "train_df = df[df['is_train'] == True].copy()\n",
    "logging.info(f\"Total training samples: {len(train_df)}\")\n",
    "\n",
    "def load_keypoints_from_directory(json_dir):\n",
    "    # ... (ì´ì „ ì½”ë“œì™€ ë™ì¼) ...\n",
    "    try:\n",
    "        json_path = Path(json_dir)\n",
    "        # ... (ì¤‘ëµ) ...\n",
    "        json_files = sorted([f for f in json_path.glob('*.json')])\n",
    "        # ... (ì¤‘ëµ) ...\n",
    "        \n",
    "        keypoints_sequence = []\n",
    "        for json_file in json_files:\n",
    "            try:\n",
    "                with open(json_file, 'r') as f:\n",
    "                    frame_data = json.load(f)\n",
    "                keypoints_sequence.append(frame_data)\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error loading {json_file}: {e}\")\n",
    "                keypoints_sequence.append(None)\n",
    "        \n",
    "        logging.info(f\" Â Loaded {len(keypoints_sequence)} frames from {json_path.name}\")\n",
    "        return keypoints_sequence\n",
    "        \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error loading from {json_dir}: {e}\")\n",
    "        return None\n",
    "\n",
    "# --- 2. ë³€í™”ìœ¨ ê¸°ë°˜ ì¹´ìš´íŒ… ë° ì‹œê°í™” í•¨ìˆ˜ ---\n",
    "\n",
    "def plot_and_count_with_derivative(keypoints_sequence, sample_name):\n",
    "    \n",
    "    if not keypoints_sequence or not keypoints_sequence[0]:\n",
    "        logging.warning(f\"Cannot count: keypoints sequence is empty or invalid for {sample_name}\")\n",
    "        return\n",
    "    \n",
    "    # 2-1. L_Elbow ê°ë„ ì¶”ì¶œ (ì´ì „ê³¼ ë™ì¼)\n",
    "    # ... (ìƒëµ: ê°ë„ ì¶”ì¶œ ë¡œì§) ...\n",
    "    angle_trajectories = {name: [] for name in ANGLE_DEFINITIONS.keys()}\n",
    "    for frame_data in keypoints_sequence:\n",
    "        current_kps = {}\n",
    "        if (frame_data and 'instance_info' in frame_data and \n",
    "            len(frame_data['instance_info']) > 0 and \n",
    "            'keypoints' in frame_data['instance_info'][0]):\n",
    "            \n",
    "            keypoints_list = frame_data['instance_info'][0]['keypoints']\n",
    "            keypoints_array = np.array(keypoints_list)\n",
    "            for idx in range(len(keypoints_array)):\n",
    "                current_kps[idx] = keypoints_array[idx, :2] \n",
    "\n",
    "        for angle_name, (p1_idx, p2_idx, p3_idx) in ANGLE_DEFINITIONS.items():\n",
    "            if all(idx in current_kps for idx in (p1_idx, p2_idx, p3_idx)):\n",
    "                angle = calculate_angle(current_kps[p1_idx], current_kps[p2_idx], current_kps[p3_idx])\n",
    "                angle_trajectories[angle_name].append(angle)\n",
    "            else:\n",
    "                angle_trajectories[angle_name].append(np.nan)\n",
    "\n",
    "    if 'L_Elbow(5-7-9)' not in angle_trajectories:\n",
    "        logging.warning(\"L_Elbow data not found in trajectories.\")\n",
    "        return\n",
    "        \n",
    "    raw_angles = np.array(angle_trajectories['L_Elbow(5-7-9)'])\n",
    "    \n",
    "    # NaN ê°’ ì²˜ë¦¬: ê²°ì¸¡ì¹˜ëŠ” ì´ì „ ìœ íš¨ ê°’ìœ¼ë¡œ ì±„ìš°ê±°ë‚˜ 0ìœ¼ë¡œ ì„¤ì • (í•„í„°ë§ì„ ìœ„í•´)\n",
    "    angles_filled = np.nan_to_num(raw_angles, nan=np.nanmean(raw_angles)) if np.nanmean(raw_angles) else np.nan_to_num(raw_angles, nan=0)\n",
    "    \n",
    "    # 2-2. ë°ì´í„° ìŠ¤ë¬´ë”© (Moving Average Filter)\n",
    "    window_size = 7 # ìœˆë„ìš° í¬ê¸°ë¥¼ ì•½ê°„ ëŠ˜ë ¤ ë¯¸ë¶„ ì‹œì˜ ë…¸ì´ì¦ˆ ì˜í–¥ì„ ì¤„ì…ë‹ˆë‹¤.\n",
    "    smoothed_angles = uniform_filter1d(angles_filled, size=window_size, mode='nearest')\n",
    "    \n",
    "    # 2-3. ë³€í™”ìœ¨ (Derivative) ê³„ì‚°\n",
    "    # np.diffëŠ” ë°°ì—´ì˜ ê¸¸ì´ë³´ë‹¤ 1 ì‘ì€ ë°°ì—´ì„ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "    derivative = np.diff(smoothed_angles)\n",
    "    \n",
    "    # 2-4. ì œë¡œ í¬ë¡œì‹± ê¸°ë°˜ ì¹´ìš´íŒ…\n",
    "    \n",
    "    # ë°”ì´ì…‰ìŠ¤ ì»¬ (íŒ”ê¿ˆì¹˜ ê°ë„ ê¸°ì¤€):\n",
    "    # ìˆ˜ì¶•(ì˜¬ë¼ê°€ëŠ” êµ¬ê°„): ê°ë„ê°€ ê°ì†Œ (Derivative < 0)\n",
    "    # ì´ì™„(ë‚´ë ¤ê°€ëŠ” êµ¬ê°„): ê°ë„ê°€ ì¦ê°€ (Derivative > 0)\n",
    "    \n",
    "    # ğŸš¨ ì¹´ìš´íŒ… ì„ê³„ê°’ (Min Velocity Threshold): ì›€ì§ì„ìœ¼ë¡œ ì¸ì •í•  ìµœì†Œ ë³€í™”ìœ¨\n",
    "    # ì •ì§€ ìƒíƒœì˜ ì‘ì€ ë…¸ì´ì¦ˆ(Jitter)ë¥¼ ë¬´ì‹œí•˜ê¸° ìœ„í•´ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "    MIN_VELOCITY_THRESHOLD = 0.5 # ì˜ˆ: 0.5 deg/frame\n",
    "    \n",
    "    rep_count = 0\n",
    "    # ìƒíƒœ: 0=ì •ì§€, 1=ìˆ˜ì¶•, 2=ì´ì™„\n",
    "    current_state = 0 \n",
    "    \n",
    "    # ì¹´ìš´íŒ… ì´ë²¤íŠ¸ ì‹œê°í™”ë¥¼ ìœ„í•œ ë¦¬ìŠ¤íŠ¸\n",
    "    count_events = []\n",
    "\n",
    "    # derivative ë°°ì—´ì€ smoothed_anglesë³´ë‹¤ 1 ì‘ìŠµë‹ˆë‹¤.\n",
    "    for i in range(len(derivative)):\n",
    "        velocity = derivative[i]\n",
    "        \n",
    "        if current_state == 0: # ì •ì§€ ë˜ëŠ” ì´ì „ ìƒíƒœë¥¼ ëª¨ë¥´ëŠ” ê²½ìš°\n",
    "            if velocity < -MIN_VELOCITY_THRESHOLD:\n",
    "                current_state = 1 # ìˆ˜ì¶• ì‹œì‘ (ê°ë„ ê°ì†Œ)\n",
    "            elif velocity > MIN_VELOCITY_THRESHOLD:\n",
    "                current_state = 2 # ì´ì™„ ì‹œì‘ (ê°ë„ ì¦ê°€)\n",
    "        \n",
    "        elif current_state == 1: # ìˆ˜ì¶• ì¤‘ (ê°ë„ ê°ì†Œ ì¤‘)\n",
    "            # ì†ë„ê°€ ì–‘ìˆ˜ ì„ê³„ê°’ì„ ë„˜ì–´ê°€ë©´ (ë°©í–¥ ì „í™˜) -> ì´ì™„ ì‹œì‘\n",
    "            if velocity > MIN_VELOCITY_THRESHOLD:\n",
    "                rep_count += 1\n",
    "                current_state = 2 # ì´ì™„ìœ¼ë¡œ ì „í™˜\n",
    "                count_events.append((i + 1, smoothed_angles[i + 1], 'REP_END')) # Rep ì™„ë£Œ ì‹œì \n",
    "        \n",
    "        elif current_state == 2: # ì´ì™„ ì¤‘ (ê°ë„ ì¦ê°€ ì¤‘)\n",
    "            # ì†ë„ê°€ ìŒìˆ˜ ì„ê³„ê°’ì„ ë„˜ì–´ê°€ë©´ (ë°©í–¥ ì „í™˜) -> ìˆ˜ì¶• ì‹œì‘\n",
    "            if velocity < -MIN_VELOCITY_THRESHOLD:\n",
    "                current_state = 1 # ìˆ˜ì¶•ìœ¼ë¡œ ì „í™˜\n",
    "                count_events.append((i + 1, smoothed_angles[i + 1], 'REP_START')) # ë‹¤ìŒ Rep ì‹œì‘ ì‹œì \n",
    "\n",
    "    \n",
    "    # 2-5. ì‹œê°í™”\n",
    "    frames = np.arange(len(smoothed_angles))\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(18, 10), sharex=True)\n",
    "    \n",
    "    fig.suptitle(f\"Derivative-based Repetition Counter for L_Elbow (Sample: {sample_name})\\nTotal Reps: {rep_count}\", fontsize=16)\n",
    "\n",
    "    # ìƒë‹¨ í”Œë¡¯: ìŠ¤ë¬´ë”©ëœ ê°ë„ ë° ì¹´ìš´íŒ… ì´ë²¤íŠ¸\n",
    "    ax_angle = axes[0]\n",
    "    ax_angle.plot(frames, smoothed_angles, label='Smoothed L_Elbow Angle', color='blue', linewidth=2)\n",
    "    ax_angle.set_title(\"Smoothed Angle Trajectory\")\n",
    "    ax_angle.set_ylabel(\"Angle (Degrees)\")\n",
    "    ax_angle.set_ylim(0, 180)\n",
    "    \n",
    "    # ì¹´ìš´íŒ… ì´ë²¤íŠ¸ í‘œì‹œ\n",
    "    for frame_idx, angle, event_type in count_events:\n",
    "        color = 'green' if event_type == 'REP_END' else 'red'\n",
    "        ax_angle.plot(frame_idx, angle, 'o', color=color, markersize=8, alpha=0.8, label=event_type if frame_idx == count_events[0][0] else \"\")\n",
    "    ax_angle.legend(loc='upper right')\n",
    "    ax_angle.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "    # í•˜ë‹¨ í”Œë¡¯: ë³€í™”ìœ¨ (ì†ë„)\n",
    "    ax_deriv = axes[1]\n",
    "    # derivativeëŠ” ê¸¸ì´ê°€ 1 ì§§ìœ¼ë¯€ë¡œ ì¸ë±ìŠ¤ë¥¼ ì¡°ì •í•˜ì—¬ í”Œë¡¯í•©ë‹ˆë‹¤.\n",
    "    ax_deriv.plot(frames[:-1], derivative, label='Angle Velocity (Derivative)', color='darkorange', linewidth=1.5)\n",
    "    \n",
    "    # ì†ë„ ì„ê³„ê°’ í‘œì‹œ (ë…¸ì´ì¦ˆ ë°©ì§€ ì˜ì—­)\n",
    "    ax_deriv.axhline(MIN_VELOCITY_THRESHOLD, color='gray', linestyle=':', label='Velocity Threshold')\n",
    "    ax_deriv.axhline(-MIN_VELOCITY_THRESHOLD, color='gray', linestyle=':')\n",
    "    ax_deriv.axhline(0, color='black', linestyle='-', linewidth=0.5)\n",
    "\n",
    "    ax_deriv.set_title(\"Angle Velocity (Change per Frame)\")\n",
    "    ax_deriv.set_xlabel(\"Frame Number\")\n",
    "    ax_deriv.set_ylabel(\"Velocity (Deg/Frame)\")\n",
    "    ax_deriv.legend(loc='upper right')\n",
    "    ax_deriv.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "    logging.info(f\"Final Repetition Count for {sample_name}: {rep_count}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# --- 3. ë°ì´í„°í”„ë ˆì„ ìˆœíšŒ ë° í”Œë¡¯ ì‹¤í–‰ ---\n",
    "\n",
    "TARGET_ACTIVITY_NAME = 'frontal__biceps_curl' \n",
    "TARGET_ACTIVITY_PATH_PATTERN = f'/{TARGET_ACTIVITY_NAME}'\n",
    "\n",
    "target_df = train_df[train_df['interp_json_path'].str.contains(TARGET_ACTIVITY_PATH_PATTERN, case=False, na=False)].copy()\n",
    "\n",
    "logging.info(\"-\" * 50)\n",
    "logging.info(f\"Plotting Derivative Counter for activity: {TARGET_ACTIVITY_NAME} (Found {len(target_df)} samples)\")\n",
    "\n",
    "NUM_SAMPLES_TO_PLOT = 1 \n",
    "\n",
    "if len(target_df) == 0:\n",
    "    logging.warning(f\"No samples found for activity: {TARGET_ACTIVITY_NAME}\")\n",
    "else:\n",
    "    for idx, row in target_df.head(NUM_SAMPLES_TO_PLOT).iterrows():\n",
    "        json_dir = row['interp_json_path']\n",
    "        sample_name = Path(json_dir).name\n",
    "        \n",
    "        logging.info(f\"Analyzing sample: {sample_name}...\")\n",
    "        \n",
    "        keypoints_sequence = load_keypoints_from_directory(json_dir)\n",
    "        \n",
    "        # ğŸš¨ ë³€í™”ìœ¨ ì¹´ìš´í„° í•¨ìˆ˜ í˜¸ì¶œ\n",
    "        plot_and_count_with_derivative(keypoints_sequence, sample_name)\n",
    "\n",
    "logging.info(\"-\" * 50)\n",
    "logging.info(\"Analysis complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
