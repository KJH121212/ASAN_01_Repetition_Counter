import pandas as pd
from pathlib import Path
from tqdm.auto import tqdm 
import numpy as np 
from typing import List, Dict, Any

# ğŸ’¡ tqdm pandas í™•ì¥ í™œì„±í™” (ìƒë‹¨ì— í•œ ë²ˆë§Œ)
tqdm.pandas()

# --- íŒŒì¼ ê²½ë¡œ ì •ì˜ ---
NEW_PATH = "/workspace/nas203/ds_RehabilitationMedicineData/IDs/tojihoo/ASAN_01_Repeatition_Counter/data/metadata.csv"
OLD_PATH = "/workspace/nas203/ds_RehabilitationMedicineData/IDs/tojihoo/ASAN_01_Repeatition_Counter/data/metadata_final.csv"

# --- í—¬í¼ í•¨ìˆ˜ ì •ì˜ ---

def count_files_in_directory(dir_path: str, extension: str = None) -> int:
    """
    ì£¼ì–´ì§„ ê²½ë¡œ ë‚´ì˜ íŒŒì¼ ê°œìˆ˜ë¥¼ ì…‰ë‹ˆë‹¤. í™•ì¥ìë¥¼ ì§€ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    """
    path_obj = Path(dir_path)
    if not path_obj.is_dir():
        return 0
    
    count = 0
    try:
        if extension:
            count = sum(1 for item in path_obj.iterdir() if item.is_file() and item.suffix.lower() == extension.lower())
        else:
            count = sum(1 for item in path_obj.iterdir() if item.is_file())
    except FileNotFoundError:
        return 0
    except PermissionError:
        print(f"[WARN] Permission denied for path: {dir_path}")
        return 0
        
    return count

def update_file_counts(df: pd.DataFrame) -> pd.DataFrame:
    """
    'frame_path'ì˜ íŒŒì¼ ê°œìˆ˜ë¥¼ 'n_frames'ì—, 'keypoints_path'ì˜ íŒŒì¼ ê°œìˆ˜ë¥¼ 'n_json'ì— ì—…ë°ì´íŠ¸í•˜ê³ 
    ì§„í–‰ ìƒíƒœë¥¼ tqdmìœ¼ë¡œ í‘œì‹œí•©ë‹ˆë‹¤.
    """
    
    print("--- n_frames / n_json ì—…ë°ì´íŠ¸ ì‹œì‘ (tqdm ì ìš©) ---")
    
    # 1. 'frame_path' ì—…ë°ì´íŠ¸ -> n_frames
    # ğŸ’¡ desc ì¸ì ì œê±°! progress_applyì— ë¬¸ì œê°€ ë°œìƒí•˜ì§€ ì•Šë„ë¡ í•©ë‹ˆë‹¤.
    df['n_frames'] = df['frame_path'].progress_apply(
        lambda p: count_files_in_directory(p, extension=".jpg")
    )
    
    # 2. 'keypoints_path' ì—…ë°ì´íŠ¸ -> n_json
    # ğŸ’¡ desc ì¸ì ì œê±°!
    df['n_json'] = df['keypoints_path'].progress_apply(
        lambda p: count_files_in_directory(p, extension=".json")
    )

    print("--- n_frames / n_json ì—…ë°ì´íŠ¸ ì™„ë£Œ ---")
    return df

# ===============================================================
# --- ë©”ì¸ ì‹¤í–‰ ë¡œì§ ---
# ===============================================================

# --- ë°ì´í„° ë¡œë“œ ---
try:
    df_new = pd.read_csv(NEW_PATH)
    df_old = pd.read_csv(OLD_PATH)
except FileNotFoundError as e:
    print(f"[FATAL] íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
    exit()

# (ì¤‘ê°„ ì—…ë°ì´íŠ¸ ë¡œì§ ìƒëµ - ë³€ê²½ ì—†ìŒ)

# 1. df_oldë¡œë¶€í„° is_train/is_val ê°’ ë³µì‚¬ ë° done í”Œë˜ê·¸ Trueë¡œ ë³€ê²½
df_old_subset = df_old[['video_path', 'is_train', 'is_val']].copy()
df_old_subset.columns = ['video_path', 'old_is_train', 'old_is_val']

df_merged = df_new.merge(df_old_subset, on='video_path', how='left')

# 3. 'is_train' ë° 'is_val' ì—´ ì—…ë°ì´íŠ¸
df_new['is_train'] = df_merged['old_is_train'].fillna(df_new['is_train'])
df_new['is_val'] = df_merged['old_is_val'].fillna(df_new['is_val'])

# 4. ëª¨ë“  '_done' í”Œë˜ê·¸ë¥¼ Trueë¡œ ì¼ê´„ ë³€ê²½
done_columns = ['frames_done', 'sapiens_done', 'reextract_done', 'overlay_done']
for col in done_columns:
    if col in df_new.columns:
        df_new[col] = True

# --- 2. íŒŒì¼ ê°œìˆ˜ ì¹´ìš´íŠ¸ ë° n_frames/n_json ì—…ë°ì´íŠ¸ (ìˆ˜ì •ëœ í•¨ìˆ˜ í˜¸ì¶œ) ---
df_new = update_file_counts(df_new)

# 5. ìµœì¢… í™•ì¸
print("\n--- ìµœì¢… ì—…ë°ì´íŠ¸ëœ df_new ìƒíƒœ (Done í”Œë˜ê·¸ì™€ ì¹´ìš´íŠ¸ í™•ì¸) ---")
print(df_new[['video_path', 'is_train', 'is_val', 'frames_done', 'sapiens_done', 'n_frames', 'n_json']].head())
print("-" * 30)

# --- 3. ì—…ë°ì´íŠ¸ëœ DataFrameì„ ì›ë³¸ CSV íŒŒì¼ì— ë®ì–´ì“°ê¸° ---
try:
    df_new.to_csv(NEW_PATH, index=False)
    print(f"\nâœ… DataFrame ì—…ë°ì´íŠ¸ ì™„ë£Œ ë° {NEW_PATH}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. (Index ì œì™¸)")
except Exception as e:
    print(f"\n[FATAL] CSV íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")