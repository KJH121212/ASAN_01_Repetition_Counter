{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecb7cdbf",
   "metadata": {},
   "source": [
    "# 개요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b59350",
   "metadata": {},
   "source": [
    "## function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66404a25",
   "metadata": {},
   "source": [
    "### Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "262ed6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/workspace/nas203/ds_RehabilitationMedicineData/IDs/tojihoo/ASAN_01_Repeatition_Counter\")\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "# --- 설정된 경로 변수 ---\n",
    "TXT_PATH = Path('/workspace/nas203/ds_RehabilitationMedicineData/IDs/tojihoo/Won_Kim_research_at_Bosanjin/M02/M02_VISIT2/segment_frames.txt')\n",
    "FRAME_PATH = Path('/workspace/nas203/ds_RehabilitationMedicineData/IDs/tojihoo/3_project_HCCmove/data/1_FRAME/Won_Kim_research_at_Bosanjin/M02_VISIT2')\n",
    "KEYPOINTS_PATH = Path('/workspace/nas203/ds_RehabilitationMedicineData/IDs/tojihoo/3_project_HCCmove/data/2_KEYPOINTS/Won_Kim_research_at_Bosanjin/M02_VISIT2')\n",
    "OUTPUT_DIR = Path('/workspace/nas203/ds_RehabilitationMedicineData/IDs/tojihoo/ASAN_01_Repeatition_Counter/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db177f22",
   "metadata": {},
   "source": [
    "### TxT parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78416daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "# 반환 타입이 확장되어 (레이블, 시작 프레임, 종료 프레임, 촬영 각도, 동작 이름)이 됩니다.\n",
    "def parse_nth_segment_info_from_file(txt_path: Path, num: int = 1) -> Optional[Tuple[str, int, int, str, str]]:\n",
    "    # 순서 번호(num) 유효성 검사\n",
    "    if num <= 0:\n",
    "        print(\"[ERROR] 순서 번호(num)는 1 이상이어야 합니다.\")\n",
    "        return None\n",
    "        \n",
    "    data_line = \"\" # ValueError에서 참조할 수 있도록 초기화\n",
    "    \n",
    "    try:\n",
    "        # 1. 파일 내용 읽기\n",
    "        with open(txt_path, 'r', encoding='utf-8') as f:\n",
    "            lines = f.readlines()\n",
    "        \n",
    "        valid_lines = []\n",
    "        # 2. 주석 (#) 라인과 빈 라인을 제외한 유효한 데이터 라인만 수집\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if line and not line.startswith('#'):\n",
    "                valid_lines.append(line)\n",
    "        \n",
    "        # 요청된 세그먼트가 존재하는지 확인\n",
    "        if len(valid_lines) < num:\n",
    "            print(f\"[ERROR] 파일에 유효한 세그먼트 데이터가 {len(valid_lines)}개 있습니다. {num}번째 세그먼트는 존재하지 않습니다.\")\n",
    "            return None\n",
    "\n",
    "        # 3. N번째 데이터 라인 파싱 (리스트 인덱스는 num - 1)\n",
    "        data_line = valid_lines[num - 1]\n",
    "        \n",
    "        # 쉼표 또는 공백으로 구분된 데이터를 파싱\n",
    "        # 예시: \"frontal__biceps_curl__1 390 1860\"\n",
    "        parts = data_line.replace(',', ' ').split() \n",
    "        \n",
    "        if len(parts) < 3:\n",
    "            print(f\"[ERROR] 데이터 라인 형식이 'label, start, end'가 아닙니다: {data_line}\")\n",
    "            return None\n",
    "\n",
    "        # 4. 프레임 정보 추출 및 타입 변환\n",
    "        full_label = parts[0].strip()\n",
    "        start_frame = int(parts[1].strip())\n",
    "        end_frame = int(parts[2].strip())\n",
    "        \n",
    "        # 5. 레이블 세분화 (추가된 부분)\n",
    "        # full_label: \"frontal__biceps_curl__1\"을 \"__\" 기준으로 분리\n",
    "        label_parts = full_label.split('__')\n",
    "        \n",
    "        if len(label_parts) >= 3:\n",
    "            # 촬영 각도(예: frontal)\n",
    "            view_angle = label_parts[0].strip()\n",
    "            # 동작 이름(예: biceps_curl)\n",
    "            action_name = label_parts[1].strip()\n",
    "            # 세트 번호(예: 1) - 현재는 사용하지 않으므로 포함하지 않아도 되지만, \n",
    "            # 일관성을 위해 label_parts[2]는 무시하고 촬영각도와 동작 이름만 반환합니다.\n",
    "        elif len(label_parts) == 2:\n",
    "             # 구분자가 부족할 경우 예외 처리\n",
    "            view_angle = label_parts[0].strip()\n",
    "            action_name = label_parts[1].strip()\n",
    "            print(f\"[WARN] 세트 번호(__1)가 없는 레이블 형식입니다. ({full_label})\")\n",
    "        else:\n",
    "            # 레이블 형식이 'A__B__C'가 아닌 경우\n",
    "            print(f\"[WARN] 레이블 형식(A__B__C)이 예상과 다릅니다. 전체 레이블 사용: {full_label}\")\n",
    "            view_angle = \"UNKNOWN\"\n",
    "            action_name = full_label\n",
    "            \n",
    "        # 전체 레이블, 시작, 종료, 촬영각도, 동작이름을 반환\n",
    "        return full_label, start_frame, end_frame, view_angle, action_name\n",
    "            \n",
    "    except FileNotFoundError:\n",
    "        print(f\"[FATAL] TXT 파일 찾을 수 없음: {txt_path}\")\n",
    "        return None\n",
    "    except ValueError as e:\n",
    "        # 프레임 번호 변환 오류 시 data_line을 표시\n",
    "        print(f\"[ERROR] 프레임 번호 변환 오류. 데이터 라인({data_line})을 확인하세요. 오류: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] 예기치 않은 오류 발생: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8039fe3f",
   "metadata": {},
   "source": [
    "#### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad82adb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('frontal__biceps_curl__1', 390, 1860, 'frontal', 'biceps_curl')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- 사용 예시 ---\n",
    "# 전역 변수 설정 (사용자 정의 경로)\n",
    "TXT_PATH = Path('/workspace/nas203/ds_RehabilitationMedicineData/IDs/tojihoo/Won_Kim_research_at_Bosanjin/M02/M02_VISIT2/segment_frames.txt')\n",
    "parse_nth_segment_info_from_file(TXT_PATH,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad15b299",
   "metadata": {},
   "source": [
    "### create video function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf0fd93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from typing import Optional, List, Any\n",
    "from functions.constants_skeleton.registry import load_skeleton_constants\n",
    "\n",
    "def render_skeleton_video(\n",
    "    frame_dir: str,\n",
    "    json_dir: str,\n",
    "    out_mp4: str,\n",
    "    start_frame: Optional[int] = None, # <--- 구간 시작 번호\n",
    "    end_frame: Optional[int] = None,   # <--- 구간 종료 번호\n",
    "    fps: int = 30,\n",
    "    kp_radius: int = 4,\n",
    "    line_thickness: int = 2,\n",
    "    model_type: str = \"coco17\",\n",
    "    flip_horizontal: bool = True\n",
    "):\n",
    "    \"\"\"\n",
    "    프레임 + keypoints JSON → skeleton overlay mp4 생성\n",
    "    - start_frame, end_frame이 지정되면 해당 구간만 처리합니다.\n",
    "    - 프레임 파일명은 6자리 0-패딩 (예: 000000.jpg)을 가정합니다.\n",
    "    - model_type: 'coco17', 'yolo12' 등 constants_skeleton에서 로드\n",
    "    - flip_horizontal: 좌우 반전 여부 (기본 False)\n",
    "    \"\"\"\n",
    "    frame_dir_path = Path(frame_dir)\n",
    "    json_dir_path = Path(json_dir)\n",
    "    out_mp4_path = Path(out_mp4)\n",
    "    out_mp4_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    frame_files: List[Path] = []\n",
    "    \n",
    "    # 1. 처리할 프레임 파일 목록 결정\n",
    "    if start_frame is not None and end_frame is not None and start_frame <= end_frame:\n",
    "        # Case 1: 시작/종료 번호가 지정된 경우\n",
    "        frame_numbers = range(start_frame, end_frame + 1)\n",
    "        # 6자리 0-패딩 파일명으로 경로를 생성합니다.\n",
    "        frame_files = [frame_dir_path / f\"{fn:06d}.jpg\" for fn in frame_numbers]\n",
    "        print(f\"[INFO] Rendering segment: Frames {start_frame} to {end_frame} ({len(frame_files)} expected).\")\n",
    "    else:\n",
    "        # Case 2: 전체 프레임 처리 (기존 glob 동작)\n",
    "        frame_files = sorted(frame_dir_path.glob(\"*.jpg\"))\n",
    "        \n",
    "        if frame_files:\n",
    "            first = frame_files[0].stem\n",
    "            last = frame_files[-1].stem\n",
    "            print(f\"[INFO] Rendering all frames ({len(frame_files)} found). Range: {first} to {last}.\")\n",
    "        else:\n",
    "            print(f\"[WARN] No frames found in {frame_dir_path} directory.\")\n",
    "            return\n",
    "\n",
    "    # 2. 상수 로드\n",
    "    const = load_skeleton_constants(model_type)\n",
    "    COLOR_SK = const.COLOR_SK\n",
    "    COLOR_L = const.COLOR_L\n",
    "    COLOR_R = const.COLOR_R\n",
    "    COLOR_NEUTRAL = const.COLOR_NEUTRAL\n",
    "    LEFT_POINTS = const.LEFT_POINTS\n",
    "    RIGHT_POINTS = const.RIGHT_POINTS\n",
    "    EXCLUDE_POINTS = getattr(const, \"EXCLUDE_POINTS\", [])\n",
    "    SKELETON_LINKS = getattr(const, \"SKELETON_LINKS\", [])\n",
    "\n",
    "    # 3. 해상도 확인 및 VideoWriter 설정\n",
    "    # 실제로 존재하는 프레임만 필터링하여 첫 번째 프레임으로 사용\n",
    "    valid_frame_paths = [p for p in frame_files if p.exists()]\n",
    "    if not valid_frame_paths:\n",
    "         print(\"[WARN] No actual frame files exist in the specified range.\")\n",
    "         return\n",
    "         \n",
    "    sample = cv2.imread(str(valid_frame_paths[0]))\n",
    "    # ⚠️ 사용자의 요청에 따라 첫 번째 프레임 로드 실패 시 오류 처리 코드를 제거했습니다.\n",
    "    # if sample is None:\n",
    "    #     print(f\"[ERROR] Could not read first valid frame: {valid_frame_paths[0]}\")\n",
    "    #     return\n",
    "        \n",
    "    h, w = sample.shape[:2]\n",
    "    \n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "    writer = cv2.VideoWriter(str(out_mp4_path), fourcc, fps, (w, h))\n",
    "    \n",
    "    if not writer.isOpened():\n",
    "        print(f\"[ERROR] VideoWriter failed to open. Check codec/path: {out_mp4_path}\")\n",
    "        return\n",
    "\n",
    "    # 4. 프레임 순회 및 렌더링\n",
    "    for frame_path in tqdm(frame_files, total=len(frame_files),\n",
    "                           desc=f\"Rendering to {out_mp4_path.name}\", unit=\"frame\"):\n",
    "                           \n",
    "        if not frame_path.exists():\n",
    "            continue # 해당 프레임이 지정된 구간에 없으면 건너뛰기\n",
    "\n",
    "        frame = cv2.imread(str(frame_path))\n",
    "        if frame is None:\n",
    "            continue\n",
    "            \n",
    "        json_path = json_dir_path / (frame_path.stem + \".json\")\n",
    "\n",
    "        if not json_path.exists():\n",
    "            writer.write(frame)\n",
    "            continue\n",
    "\n",
    "        # JSON 로드 및 렌더링\n",
    "        try:\n",
    "            with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "            if \"instance_info\" in data and len(data[\"instance_info\"]) > 0:\n",
    "                for person in data[\"instance_info\"]:\n",
    "                    kpts = np.array(person.get(\"keypoints\", []))\n",
    "\n",
    "                    if kpts.ndim != 2 or kpts.shape[0] == 0:\n",
    "                        continue\n",
    "\n",
    "                    # Skeleton 라인\n",
    "                    for i, j in SKELETON_LINKS:\n",
    "                        if i >= len(kpts) or j >= len(kpts) or i in EXCLUDE_POINTS or j in EXCLUDE_POINTS:\n",
    "                            continue\n",
    "                        \n",
    "                        # 좌표 유효성 검사 (0보다 큰 값)\n",
    "                        pt1_x, pt1_y = kpts[i]\n",
    "                        pt2_x, pt2_y = kpts[j]\n",
    "                        if pt1_x <= 0 or pt1_y <= 0 or pt2_x <= 0 or pt2_y <= 0:\n",
    "                             continue\n",
    "                             \n",
    "                        pt1, pt2 = tuple(map(int, kpts[i])), tuple(map(int, kpts[j]))\n",
    "                        cv2.line(frame, pt1, pt2, COLOR_SK, line_thickness)\n",
    "\n",
    "                    # Keypoints 점\n",
    "                    for idx, (x, y) in enumerate(kpts):\n",
    "                        if idx in EXCLUDE_POINTS or x <= 0 or y <= 0:\n",
    "                            continue\n",
    "                        if idx in LEFT_POINTS:\n",
    "                            color = COLOR_L\n",
    "                        elif idx in RIGHT_POINTS:\n",
    "                            color = COLOR_R\n",
    "                        else:\n",
    "                            color = COLOR_NEUTRAL\n",
    "                        cv2.circle(frame, (int(x), int(y)), kp_radius, color, -1)\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] JSON processing error for {frame_path.stem}: {e}\")\n",
    "            # 오류 발생 시 스켈레톤 없이 원본 프레임만 기록\n",
    "            pass \n",
    "\n",
    "        # 안내 문구 및 프레임 번호 표시\n",
    "        frame_num_int = int(frame_path.stem)\n",
    "        legend_text = f\"L: Blue | R: Red | Frame: {frame_num_int}\"\n",
    "        cv2.putText(frame, legend_text, (20, h - 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "        # 좌우 반전 (선택)\n",
    "        if flip_horizontal:\n",
    "            frame = cv2.flip(frame, 1)\n",
    "\n",
    "        writer.write(frame)\n",
    "\n",
    "    writer.release()\n",
    "    print(f\"✅ Skeleton overlay 완료 → {out_mp4_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6e647c",
   "metadata": {},
   "source": [
    "#### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "411557a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # ----------------------------------------------------------------------\n",
    "# # 예시 실행 코드 (경로 및 실행 설정)\n",
    "# # ----------------------------------------------------------------------\n",
    "\n",
    "# # ⚠️ 이 경로는 사용자의 환경에 맞춰 실제 데이터 경로로 변경되어야 합니다.\n",
    "# FRAME_DIR = '/workspace/nas203/ds_RehabilitationMedicineData/IDs/tojihoo/3_project_HCCmove/data/1_FRAME/Won_Kim_research_at_Bosanjin/M02_VISIT2'\n",
    "# JSON_DIR = '/workspace/nas203/ds_RehabilitationMedicineData/IDs/tojihoo/3_project_HCCmove/data/2_KEYPOINTS/Won_Kim_research_at_Bosanjin/M02_VISIT2'\n",
    "# OUTPUT_DIR = '/workspace/nas203/ds_RehabilitationMedicineData/IDs/tojihoo/ASAN_01_Repeatition_Counter/'\n",
    "# OUTPUT_DIR_PATH = Path(OUTPUT_DIR)\n",
    "# OUTPUT_DIR_PATH.mkdir(exist_ok=True)\n",
    "\n",
    "# # --- 실행 1: 특정 구간만 렌더링 (start/end num 지정) ---\n",
    "# # 예시: 프레임 100부터 150까지 렌더링\n",
    "# OUT_FILE_SEGMENT = OUTPUT_DIR_PATH / \"segment_100_150.mp4\"\n",
    "# print(\"\\n--- [실행 1] 특정 구간 렌더링 (프레임 100~150) ---\")\n",
    "\n",
    "# render_skeleton_video(\n",
    "#     frame_dir=FRAME_DIR,\n",
    "#     json_dir=JSON_DIR,\n",
    "#     out_mp4=str(OUT_FILE_SEGMENT),\n",
    "#     start_frame=100,\n",
    "#     end_frame=150,\n",
    "#     flip_horizontal=False \n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1b6256",
   "metadata": {},
   "source": [
    "### load_kpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4220d1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Dict, Any\n",
    "\n",
    "def load_kpt(\n",
    "    json_dir: str,\n",
    "    start_frame: int,\n",
    "    end_frame: int\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    지정된 디렉토리에서 시작 프레임부터 끝 프레임까지의 키포인트 JSON 파일을 로드하고,\n",
    "    'keypoint_id2name', 'skeleton_links'는 메타 정보로 한 번만 추출하며,\n",
    "    'instance_info'는 프레임별로 추출하여 단일 딕셔너리로 반환합니다.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 최종 결과 딕셔너리 초기화\n",
    "    result_data = {\n",
    "        'meta_info': {},  # keypoint_id2name, skeleton_links 저장\n",
    "        'frame_data': []  # (프레임 번호, instance_info) 리스트 저장\n",
    "    }\n",
    "    \n",
    "    base_path = Path(json_dir)\n",
    "    meta_loaded = False\n",
    "    \n",
    "    # 1. 프레임 순회 및 파일 경로 조합\n",
    "    for frame_num in range(start_frame, end_frame + 1): \n",
    "        \n",
    "        filename = f\"{frame_num:06d}.json\" \n",
    "        json_path = base_path / filename\n",
    "\n",
    "        # 2. JSON 로드 및 데이터 필터링\n",
    "        try:\n",
    "            with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                data = json.load(f)\n",
    "            \n",
    "            # 메타 정보는 첫 번째 프레임에서 한 번만 추출하여 저장\n",
    "            if not meta_loaded:\n",
    "                meta_info = data.get('meta_info', {})\n",
    "                result_data['meta_info'] = {\n",
    "                    'keypoint_id2name': meta_info.get('keypoint_id2name', {}),\n",
    "                    'skeleton_links': meta_info.get('skeleton_links', []),\n",
    "                }\n",
    "                meta_loaded = True\n",
    "            \n",
    "            # 인스턴스 ID 할당\n",
    "            instance_info = data.get('instance_info', [])\n",
    "            processed_instances = []\n",
    "            for i, instance in enumerate(instance_info):\n",
    "                # 인스턴스 리스트 인덱스를 1부터 시작하는 ID로 할당\n",
    "                # (프레임 내에서 '1번 사람', '2번 사람'으로 구분)\n",
    "                instance['instance_id'] = i + 1 \n",
    "                processed_instances.append(instance)\n",
    "\n",
    "            # (프레임 번호, 인스턴스 정보 리스트) 형태로 저장\n",
    "            result_data['frame_data'].append((frame_num, processed_instances))\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Error: JSON decoding failed for {json_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred while loading {json_path}: {e}\")\n",
    "            \n",
    "    return result_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a30245",
   "metadata": {},
   "source": [
    "#### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35e550cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An unexpected error occurred while loading /workspace/nas203/ds_RehabilitationMedicineData/IDs/tojihoo/3_project_HCCmove/data/2_KEYPOINTS/Won_Kim_research_at_Bosanjin/M02_VISIT2/000005.json: [Errno 2] No such file or directory: '/workspace/nas203/ds_RehabilitationMedicineData/IDs/tojihoo/3_project_HCCmove/data/2_KEYPOINTS/Won_Kim_research_at_Bosanjin/M02_VISIT2/000005.json'\n",
      "An unexpected error occurred while loading /workspace/nas203/ds_RehabilitationMedicineData/IDs/tojihoo/3_project_HCCmove/data/2_KEYPOINTS/Won_Kim_research_at_Bosanjin/M02_VISIT2/000006.json: [Errno 2] No such file or directory: '/workspace/nas203/ds_RehabilitationMedicineData/IDs/tojihoo/3_project_HCCmove/data/2_KEYPOINTS/Won_Kim_research_at_Bosanjin/M02_VISIT2/000006.json'\n",
      "<class 'dict'>\n",
      "An unexpected error occurred while loading /workspace/nas203/ds_RehabilitationMedicineData/IDs/tojihoo/3_project_HCCmove/data/2_KEYPOINTS/Won_Kim_research_at_Bosanjin/M02_VISIT2/000005.json: [Errno 2] No such file or directory: '/workspace/nas203/ds_RehabilitationMedicineData/IDs/tojihoo/3_project_HCCmove/data/2_KEYPOINTS/Won_Kim_research_at_Bosanjin/M02_VISIT2/000005.json'\n",
      "An unexpected error occurred while loading /workspace/nas203/ds_RehabilitationMedicineData/IDs/tojihoo/3_project_HCCmove/data/2_KEYPOINTS/Won_Kim_research_at_Bosanjin/M02_VISIT2/000006.json: [Errno 2] No such file or directory: '/workspace/nas203/ds_RehabilitationMedicineData/IDs/tojihoo/3_project_HCCmove/data/2_KEYPOINTS/Won_Kim_research_at_Bosanjin/M02_VISIT2/000006.json'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'meta_info': {}, 'frame_data': []}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(load_kpt(KEYPOINTS_PATH,5,6)))\n",
    "load_kpt(KEYPOINTS_PATH,5,6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa703de4",
   "metadata": {},
   "source": [
    "### Calculate Angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "848abbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_angle(a, b, c):\n",
    "    a = np.array(a) # 첫 번째 점을 numpy 배열로 변환\n",
    "    b = np.array(b) # 중간 점을 numpy 배열로 변환\n",
    "    c = np.array(c) # 세 번째 점을 numpy 배열로 변환\n",
    "\n",
    "    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0]) # 아크탄젠트를 이용해 라디안 각도 계산\n",
    "    angle = np.abs(radians*180.0/np.pi) # 라디안을 도(degree) 단위로 변환하고 절대값 취함\n",
    "\n",
    "    if angle > 180.0: # 각도가 180도를 넘어가면\n",
    "        angle = 360 - angle # 360도에서 뺀 값을 사용하여 내각을 구함\n",
    "\n",
    "    return angle # 계산된 각도 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971e0b52",
   "metadata": {},
   "source": [
    "### track_keypoints_with_heuristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00b60960",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Dict, Any, List, Tuple\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "# --- 헬퍼 함수 1: IOU 계산 ---\n",
    "def calculate_iou(boxA: List[float], boxB: List[float]) -> float:\n",
    "\n",
    "    # 좌표 추출\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    "\n",
    "    # 교차 영역 계산 (겹치지 않으면 0)\n",
    "    interArea = max(0, xB - xA) * max(0, yB - yA)\n",
    "    \n",
    "    # 두 박스의 개별 영역 계산\n",
    "    boxAArea = (boxA[2] - boxA[0]) * (boxA[3] - boxA[1])\n",
    "    boxBArea = (boxB[2] - boxB[0]) * (boxB[3] - boxB[1])\n",
    "\n",
    "    # IOU 계산: 교차 영역 / 합집합 영역\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "    return iou\n",
    "\n",
    "# Pose 유사도 검사\n",
    "def calculate_pose_distance(kpts_t: List[List[float]], kpts_t_plus_1: List[List[float]]) -> float:\n",
    "       \n",
    "    # 1. 키포인트 벡터 평탄화 (Flatten)\n",
    "    vec_t = np.array(kpts_t).flatten()\n",
    "    vec_t_plus_1 = np.array(kpts_t_plus_1).flatten()\n",
    "\n",
    "    # 2. 정규화 (예시: 모든 키포인트를 평균 위치를 기준으로 이동)\n",
    "    # 실제 Pose 트래킹에서는 BBox나 특정 관절(예: 엉덩이 중앙)을 기준으로 스케일 및 위치를 정규화해야 정확함.\n",
    "    # 여기서는 간단히 전체 평균을 이용해 위치만 정규화합니다.\n",
    "    \n",
    "    if len(vec_t) != len(vec_t_plus_1) or len(vec_t) == 0:\n",
    "        return float('inf')\n",
    "\n",
    "    # 중심점 이동 (Center Shift Normalization)\n",
    "    center_t = np.mean(vec_t.reshape(-1, 2), axis=0)\n",
    "    center_t_plus_1 = np.mean(vec_t_plus_1.reshape(-1, 2), axis=0)\n",
    "    \n",
    "    # 정규화된 벡터 생성 (중심점 위치 이동)\n",
    "    norm_vec_t = vec_t.reshape(-1, 2) - center_t\n",
    "    norm_vec_t_plus_1 = vec_t_plus_1.reshape(-1, 2) - center_t_plus_1\n",
    "    \n",
    "    # 3. L2 거리 (유클리드 거리) 계산\n",
    "    # 거리가 작을수록 자세가 유사함\n",
    "    return euclidean(norm_vec_t.flatten(), norm_vec_t_plus_1.flatten())\n",
    "\n",
    "# --- 메인 트래킹 함수 ---\n",
    "def track_keypoints_with_heuristics(\n",
    "    data: Dict[str, Any],\n",
    "    iou_threshold: float = 0.5,\n",
    "    max_center_distance: float = 150.0 # 픽셀 단위 최대 이동 거리 가정\n",
    ") -> Dict[str, Any]:\n",
    "    \n",
    "    tracked_data = data.copy()\n",
    "    \n",
    "    # 1. 트래커 상태 초기화\n",
    "    current_tid_counter = 1000  # TID는 1000부터 시작 (재활용되지 않음)\n",
    "    # {TID: {'center': (x, y), 'bbox': [x1, y1, x2, y2], 'kpts': [[x, y], ...], 'lost_count': 0}}\n",
    "    active_trackers = {} \n",
    "\n",
    "    # 2. BBox 형식 변환 헬퍼 함수\n",
    "    def get_bbox_coord(instance):\n",
    "        # instance['bbox']가 [[x1, y1, x2, y2]] 형태이므로 첫 번째 요소를 사용\n",
    "        return instance['bbox'][0]\n",
    "    \n",
    "    def get_bbox_center(box):\n",
    "        return ((box[0] + box[2]) / 2, (box[1] + box[3]) / 2)\n",
    "\n",
    "    # 3. 프레임 순회하며 트래킹 수행\n",
    "    new_frame_data = []\n",
    "    for frame_num, current_instances in tracked_data['frame_data']:\n",
    "        \n",
    "        # 현재 프레임에 TID를 부여할 딕셔너리 리스트\n",
    "        instances_with_tid = [] \n",
    "        \n",
    "        # 현재 프레임의 인스턴스 중 아직 매칭되지 않은 인스턴스의 인덱스 리스트\n",
    "        unmatched_new_indices = list(range(len(current_instances)))\n",
    "        \n",
    "        # 다음 프레임 추적을 위한 트래커 업데이트 딕셔너리\n",
    "        next_active_trackers = {}\n",
    "        \n",
    "        # --- A. 계층적 매칭 단계 (현재 TID를 새로운 인스턴스와 매칭) ---\n",
    "        \n",
    "        for tid, tracker_state in active_trackers.items():\n",
    "            \n",
    "            best_match_index = -1\n",
    "            best_iou = 0.0\n",
    "            min_center_dist = float('inf')\n",
    "            min_pose_dist = float('inf')\n",
    "            \n",
    "            matched_by_iou = False\n",
    "            matched_by_dist = False\n",
    "\n",
    "            # 매칭되지 않은 새로운 인스턴스들만 확인\n",
    "            for i in unmatched_new_indices:\n",
    "                new_instance = current_instances[i]\n",
    "                new_bbox = get_bbox_coord(new_instance)\n",
    "                \n",
    "                # 1순위: IOU 기반 매칭\n",
    "                iou = calculate_iou(tracker_state['bbox'], new_bbox)\n",
    "                if iou >= iou_threshold and iou > best_iou:\n",
    "                    best_iou = iou\n",
    "                    best_match_index = i\n",
    "                    matched_by_iou = True\n",
    "                \n",
    "                # 2순위: 중심점 거리 기반 매칭 (IOU 매칭이 없거나 약할 경우 대비)\n",
    "                new_center = get_bbox_center(new_bbox)\n",
    "                center_dist = euclidean(tracker_state['center'], new_center)\n",
    "                if center_dist <= max_center_distance and center_dist < min_center_dist:\n",
    "                    min_center_dist = center_dist\n",
    "                    # IOU 매칭이 안됐거나, 현재 거리 매칭이 IOU 매칭보다 더 나은 대안일 경우를 고려\n",
    "                    if not matched_by_iou and best_iou < iou_threshold:\n",
    "                         best_match_index = i\n",
    "                         matched_by_dist = True\n",
    "            \n",
    "            # --- B. 매칭 결과 처리 ---\n",
    "            \n",
    "            # 1. IOU나 거리로 확실한 매칭이 된 경우\n",
    "            if best_match_index != -1 and (best_iou >= iou_threshold or min_center_dist < max_center_distance):\n",
    "                matched_instance = current_instances[best_match_index]\n",
    "                \n",
    "                # Pose 유사도 검증 (선택적: 유사도가 너무 낮으면 매칭을 거부할 수도 있음)\n",
    "                pose_dist = calculate_pose_distance(tracker_state['kpts'], matched_instance['keypoints'])\n",
    "                # if pose_dist > 500: # 예시 임계값\n",
    "                #    continue # Pose가 너무 다르면 매칭 거부\n",
    "                \n",
    "                # 매칭된 인스턴스에 TID 할당 및 업데이트\n",
    "                matched_instance['track_id'] = tid\n",
    "                instances_with_tid.append(matched_instance)\n",
    "                unmatched_new_indices.remove(best_match_index)\n",
    "                \n",
    "                # 트래커 상태 업데이트\n",
    "                next_active_trackers[tid] = {\n",
    "                    'center': get_bbox_center(get_bbox_coord(matched_instance)),\n",
    "                    'bbox': get_bbox_coord(matched_instance),\n",
    "                    'kpts': matched_instance['keypoints'],\n",
    "                    'lost_count': 0\n",
    "                }\n",
    "            \n",
    "            # 2. 매칭 실패 (LOST 상태)\n",
    "            else:\n",
    "                new_lost_count = tracker_state['lost_count'] + 1\n",
    "                if new_lost_count <= 5: # 5프레임 동안 못 찾으면 트랙 종료\n",
    "                    # 상태만 업데이트하여 다음 프레임에서 재시도\n",
    "                    tracker_state['lost_count'] = new_lost_count\n",
    "                    next_active_trackers[tid] = tracker_state\n",
    "                # else: 5프레임 이상이면 트랙 종료 (next_active_trackers에 추가 안함)\n",
    "\n",
    "        # --- C. 신규 인스턴스 (New Track Initialization) ---\n",
    "        \n",
    "        for i in unmatched_new_indices:\n",
    "            new_instance = current_instances[i]\n",
    "            \n",
    "            # 신규 TID 할당\n",
    "            current_tid_counter += 1\n",
    "            new_tid = current_tid_counter\n",
    "            \n",
    "            new_instance['track_id'] = new_tid\n",
    "            instances_with_tid.append(new_instance)\n",
    "\n",
    "            # 새 트래커 상태 초기화\n",
    "            next_active_trackers[new_tid] = {\n",
    "                'center': get_bbox_center(get_bbox_coord(new_instance)),\n",
    "                'bbox': get_bbox_coord(new_instance),\n",
    "                'kpts': new_instance['keypoints'],\n",
    "                'lost_count': 0\n",
    "            }\n",
    "            \n",
    "        # 4. 트래커 상태 업데이트 및 결과 저장\n",
    "        active_trackers = next_active_trackers\n",
    "        new_frame_data.append((frame_num, instances_with_tid))\n",
    "\n",
    "    # 5. 최종 데이터 반환\n",
    "    tracked_data['frame_data'] = new_frame_data\n",
    "    return tracked_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2675b9f5",
   "metadata": {},
   "source": [
    "### create_skeleton_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6cd974a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from typing import Dict, Any, List, Tuple\n",
    "from pathlib import Path\n",
    "\n",
    "# --- 전역 상수 ---\n",
    "TRACK_COLORS = [(0, 0, 255), (0, 255, 0), (255, 0, 0), (0, 255, 255), (255, 0, 255), (255, 255, 0), (128, 0, 0), (0, 128, 0), (0, 0, 128), (128, 128, 0), (128, 0, 128), (0, 128, 128)]\n",
    "# 비디오 프레임 크기 (원본 이미지 크기에 맞게 설정해야 합니다.)\n",
    "FRAME_WIDTH = 1280 \n",
    "FRAME_HEIGHT = 720 \n",
    "\n",
    "# --- 핵심 시각화 함수 (검은 배경 사용) ---\n",
    "def draw_skeleton_on_black(\n",
    "    frame_data_list: List[Dict[str, Any]], \n",
    "    skeleton_links: List[Tuple[int, int]]\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    검은색 배경에 스켈레톤, BBox, Track ID를 그립니다.\n",
    "    \"\"\"\n",
    "    # 1. 검은색 캔버스 생성 (FRAME_HEIGHT x FRAME_WIDTH)\n",
    "    img = np.zeros((FRAME_HEIGHT, FRAME_WIDTH, 3), dtype=np.uint8)\n",
    "\n",
    "    # 2. 인스턴스 정보 순회 (Track ID 기반 시각화)\n",
    "    for instance in frame_data_list:\n",
    "        track_id = instance.get('track_id')\n",
    "        kpts = np.array(instance['keypoints'], dtype=np.int32)\n",
    "        bbox = instance['bbox'][0]  # [[x1, y1, x2, y2]] 형태 가정\n",
    "\n",
    "        if track_id is None:\n",
    "            continue\n",
    "            \n",
    "        # Track ID에 따른 고유 색상 설정\n",
    "        color_idx = track_id % len(TRACK_COLORS)\n",
    "        color = TRACK_COLORS[color_idx]\n",
    "        \n",
    "        # A. Bounding Box 및 Track ID 그리기\n",
    "        x1, y1, x2, y2 = map(int, bbox)\n",
    "        \n",
    "        # BBox 그리기 (선 두께 2)\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), color, 2)\n",
    "        \n",
    "        # Track ID 텍스트 오버레이\n",
    "        text = f\"ID: {track_id}\"\n",
    "        cv2.putText(img, text, (x1, y1 - 10), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "\n",
    "        # B. Skeleton (골격) 그리기\n",
    "        for start_idx, end_idx in skeleton_links:\n",
    "            if start_idx < len(kpts) and end_idx < len(kpts):\n",
    "                start_point = tuple(kpts[start_idx])\n",
    "                end_point = tuple(kpts[end_idx])\n",
    "                # 스켈레톤 선 그리기\n",
    "                cv2.line(img, start_point, end_point, color, 2)\n",
    "\n",
    "        # C. Keypoints (관절점) 그리기\n",
    "        for pt in kpts:\n",
    "            cv2.circle(img, tuple(pt), 4, (255, 255, 255), -1) \n",
    "            cv2.circle(img, tuple(pt), 2, color, -1)\n",
    "\n",
    "    return img\n",
    "\n",
    "# --- 비디오 생성 로직 (이미지 로드 제거) ---\n",
    "def create_skeleton_video(\n",
    "    tracking_data: Dict[str, Any], \n",
    "    output_video_path: str,\n",
    "    fps: int = 30\n",
    "):\n",
    "    \"\"\"\n",
    "    추적 결과를 기반으로 검은색 배경의 스켈레톤 비디오 파일을 생성합니다.\n",
    "    \"\"\"\n",
    "    frame_data_list = tracking_data['frame_data']\n",
    "    meta_links = tracking_data['meta_info'].get('skeleton_links', [])\n",
    "    \n",
    "    if not frame_data_list or not meta_links:\n",
    "        print(\"프레임 데이터 또는 골격 연결 정보가 없습니다.\")\n",
    "        return\n",
    "\n",
    "    # 비디오 라이터 설정 (전역 변수 FRAME_WIDTH, FRAME_HEIGHT 사용)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (FRAME_WIDTH, FRAME_HEIGHT))\n",
    "\n",
    "    print(f\"검은 배경 비디오 생성 시작: {output_video_path}...\")\n",
    "    \n",
    "    # 모든 프레임을 순회하며 시각화 및 저장\n",
    "    for frame_num, instances in frame_data_list:\n",
    "        \n",
    "        # 스켈레톤만 그리는 함수 호출\n",
    "        visualized_img = draw_skeleton_on_black(\n",
    "            instances, \n",
    "            meta_links\n",
    "        )\n",
    "        \n",
    "        if visualized_img is not None:\n",
    "            out.write(visualized_img)\n",
    "        \n",
    "    out.release()\n",
    "    print(\"비디오 생성 완료.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0fcea0",
   "metadata": {},
   "source": [
    "### extract_main_patient_data\n",
    "중앙에 위치하면서 BBox가 가장 큰 환자의 TID 를 찾고 patient_data로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1c3ad33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Dict, Any, Optional, List\n",
    "\n",
    "# 전역 상수 (화질 및 ROI 설정)\n",
    "FRAME_WIDTH = 1280\n",
    "FRAME_HEIGHT = 720\n",
    "ROI_CENTER = (FRAME_WIDTH // 2, FRAME_HEIGHT // 2)\n",
    "ROI_TOLERANCE = 200 # 중앙에서 200픽셀 내의 영역\n",
    "\n",
    "def extract_main_patient_data(tracking_data: Dict[str, Any]) -> Optional[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    트래킹 데이터에서 중앙에 위치하며 가장 큰 BBox를 가진 환자를 식별하고,\n",
    "    해당 환자의 데이터만 필터링하여 반환합니다.\n",
    "    \n",
    "    Returns:\n",
    "        필터링된 tracking_data (메인 환자만 포함) 또는 None\n",
    "    \"\"\"\n",
    "    frame_data_list = tracking_data.get('frame_data', [])\n",
    "    if not frame_data_list:\n",
    "        return None\n",
    "\n",
    "    # 분석할 프레임 수 (초반 5프레임 분석)\n",
    "    ANALYSIS_FRAMES = 5\n",
    "    \n",
    "    # {TID: [총 BBox 면적 합, 횟수]}\n",
    "    tid_metrics = {}\n",
    "    \n",
    "    # 1. 초기 프레임 분석하여 메인 환자 TID 찾기\n",
    "    for i, (frame_num, instances) in enumerate(frame_data_list):\n",
    "        if i >= ANALYSIS_FRAMES:\n",
    "            break\n",
    "\n",
    "        for instance in instances:\n",
    "            tid = instance.get('track_id')\n",
    "            if tid is None:\n",
    "                continue\n",
    "\n",
    "            bbox = instance['bbox'][0] # [x1, y1, x2, y2]\n",
    "            \n",
    "            # 중앙 근접성 확인\n",
    "            x1, y1, x2, y2 = bbox\n",
    "            center_x = (x1 + x2) / 2\n",
    "            center_y = (y1 + y2) / 2\n",
    "            \n",
    "            # 중앙 ROI 기준 충족 여부\n",
    "            is_central = (\n",
    "                abs(center_x - ROI_CENTER[0]) < ROI_TOLERANCE and\n",
    "                abs(center_y - ROI_CENTER[1]) < ROI_TOLERANCE\n",
    "            )\n",
    "            \n",
    "            if is_central:\n",
    "                # BBox 면적 계산\n",
    "                bbox_area = (x2 - x1) * (y2 - y1)\n",
    "                \n",
    "                if tid not in tid_metrics:\n",
    "                    tid_metrics[tid] = [0, 0] # [면적 합, 횟수]\n",
    "                \n",
    "                tid_metrics[tid][0] += bbox_area\n",
    "                tid_metrics[tid][1] += 1\n",
    "\n",
    "    if not tid_metrics:\n",
    "        print(\"경고: 중앙 ROI 내에 적합한 인스턴스가 없습니다. (TID를 찾을 수 없음)\")\n",
    "        return None\n",
    "\n",
    "    # 2. 평균 면적이 가장 큰 TID 선택\n",
    "    best_tid = None\n",
    "    max_avg_area = -1\n",
    "\n",
    "    for tid, (area_sum, count) in tid_metrics.items():\n",
    "        if count > 0:\n",
    "            avg_area = area_sum / count\n",
    "            \n",
    "            if avg_area > max_avg_area:\n",
    "                max_avg_area = avg_area\n",
    "                best_tid = tid\n",
    "\n",
    "    # 3. 해당 TID 데이터만 필터링\n",
    "    filtered_data = tracking_data.copy()\n",
    "    new_frame_data = []\n",
    "\n",
    "    for frame_num, instances in tracking_data['frame_data']:\n",
    "        # 해당 TID만 찾아서 리스트에 저장\n",
    "        patient_instance = [inst for inst in instances if inst.get('track_id') == best_tid]\n",
    "        \n",
    "        if patient_instance:\n",
    "            new_frame_data.append((frame_num, patient_instance))\n",
    "\n",
    "    filtered_data['frame_data'] = new_frame_data\n",
    "    \n",
    "    return filtered_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b662b29",
   "metadata": {},
   "source": [
    "### New fuction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3793cc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "import numpy as np\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "\n",
    "class BaseRepetitionCounter(ABC):\n",
    "   \n",
    "    def __init__(self, view_angle: str):\n",
    "        self.view_angle = view_angle\n",
    "        self.count = 0\n",
    "        self.state = \"neutral\"\n",
    "        self.previous_value = None\n",
    "        \n",
    "    def normalize_skeleton(self, skeleton: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n",
    "        \"\"\"\n",
    "        공통 Normalization 로직\n",
    "        - Hip center를 원점으로\n",
    "        - Torso length로 스케일 정규화\n",
    "        \"\"\"\n",
    "        hip = skeleton.get('hip_center') or skeleton.get('pelvis')\n",
    "        normalized = {}\n",
    "        \n",
    "        for joint_name, joint_pos in skeleton.items():\n",
    "            normalized[joint_name] = joint_pos - hip\n",
    "        \n",
    "        # Torso length 계산\n",
    "        neck = normalized.get('neck') or normalized.get('head')\n",
    "        pelvis = normalized.get('pelvis') or normalized.get('hip_center')\n",
    "        torso_length = np.linalg.norm(neck - pelvis)\n",
    "        \n",
    "        for joint_name in normalized:\n",
    "            normalized[joint_name] = normalized[joint_name] / torso_length\n",
    "        \n",
    "        return normalized\n",
    "    \n",
    "    @abstractmethod\n",
    "    def get_key_joints(self) -> List[str]:\n",
    "        \"\"\"각 운동에서 추적할 주요 관절 반환\"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def get_thresholds(self) -> Dict[str, float]:\n",
    "        \"\"\"View angle에 따른 threshold 반환\"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def update(self, skeleton: Dict[str, np.ndarray]) -> bool:\n",
    "        \"\"\"\n",
    "        프레임별로 호출되어 상태 업데이트 및 카운팅\n",
    "        Returns: 카운트가 증가했으면 True\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"카운터 리셋\"\"\"\n",
    "        self.count = 0\n",
    "        self.state = \"neutral\"\n",
    "        self.previous_value = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc95ce9e",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7120e37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "TARGET_VIDEO_DIR = 'M02'\n",
    "TARGET_VIDEO = 'M02_VISIT2'\n",
    "\n",
    "TXT_DIR = Path(\"/workspace/nas203/ds_RehabilitationMedicineData/IDs/tojihoo/Won_Kim_research_at_Bosanjin/\")\n",
    "FRAME_DIR = Path(\"/workspace/nas203/ds_RehabilitationMedicineData/IDs/tojihoo/3_project_HCCmove/data/1_FRAME/Won_Kim_research_at_Bosanjin/\")\n",
    "KEYPOINTS_DIR = Path(\"/workspace/nas203/ds_RehabilitationMedicineData/IDs/tojihoo/3_project_HCCmove/data/2_KEYPOINTS/Won_Kim_research_at_Bosanjin/\")\n",
    "OUTPUT_DIR = Path('/workspace/nas203/ds_RehabilitationMedicineData/IDs/tojihoo/ASAN_01_Repeatition_Counter/')\n",
    "\n",
    "TXT_PATH = TXT_DIR / TARGET_VIDEO_DIR / TARGET_VIDEO / \"segment_frames.txt\"\n",
    "FRAME_PATH = FRAME_DIR / TARGET_VIDEO_DIR / TARGET_VIDEO\n",
    "KEYPOINTS_PATH = KEYPOINTS_DIR / TARGET_VIDEO_DIR / TARGET_VIDEO \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "826e1656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('frontal__biceps_curl__1', 390, 1860, 'frontal', 'biceps_curl')\n"
     ]
    }
   ],
   "source": [
    "full_label, start_frame, end_frame, view_angle, action_name = parse_nth_segment_info_from_file(TXT_PATH,1)\n",
    "print(parse_nth_segment_info_from_file(TXT_PATH,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6fad3ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'keypoint_id2name': {'0': 'nose', '1': 'left_eye', '2': 'right_eye', '3': 'left_ear', '4': 'right_ear', '5': 'left_shoulder', '6': 'right_shoulder', '7': 'left_elbow', '8': 'right_elbow', '9': 'left_wrist', '10': 'right_wrist', '11': 'left_hip', '12': 'right_hip', '13': 'left_knee', '14': 'right_knee', '15': 'left_ankle', '16': 'right_ankle'}, 'skeleton_links': [[15, 13], [13, 11], [16, 14], [14, 12], [11, 12], [5, 11], [6, 12], [5, 6], [5, 7], [6, 8], [7, 9], [8, 10], [1, 2], [0, 1], [0, 2], [1, 3], [2, 4], [3, 5], [4, 6]]}\n"
     ]
    }
   ],
   "source": [
    "data = load_kpt(KEYPOINTS_PATH,start_frame,end_frame)\n",
    "print(data['meta_info'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a0c1fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(390, [{'keypoints': [[623.116569494809, 276.58871374999944], [632.0300657182678, 273.26429975043493], [617.213324244178, 275.89828321752134], [652.723818741729, 286.16960966286035], [608.6365766619523, 290.1093789921881], [687.9399624990729, 337.98545105249127], [583.0273832350395, 338.896641384624], [709.1141864235723, 396.6670181435643], [560.640438566923, 407.75919326930034], [723.8945584481885, 433.93101430077877], [539.0682291890646, 444.8229061857852], [660.440203605054, 447.5955943565432], [590.9682451102794, 445.6246015097727], [679.5426441589224, 503.388014915476], [575.1900484220305, 499.49022418594745], [684.0827803298957, 620.3137314261102], [562.2892200664218, 618.7605232335299]], 'keypoint_scores': [0.04641585797071457, 0.04142773523926735, 0.03796147555112839, 0.04945866018533707, 0.029720377177000046, 0.11248690634965897, 0.08959366381168365, 0.12298426777124405, 0.09696049988269806, 0.1587880253791809, 0.12082652747631073, 0.08149617910385132, 0.07353484630584717, 0.07115766406059265, 0.07012289762496948, 0.06569511443376541, 0.07293447852134705], 'bbox': [[502.62579345703125, 241.64248657226562, 760.92529296875, 683.9012451171875]], 'bbox_score': 1.0, 'instance_id': 1, 'track_id': 1001}, {'keypoints': [[1035.3002665288702, 399.8481518098167], [1040.1133215535378, 392.1153783776783], [1032.7280411434638, 399.95551812319843], [1061.4472009103663, 389.5831556676193], [1028.187783714579, 407.55537119198266], [1103.126743480112, 412.77206345398076], [1039.5795192736596, 436.5235398217817], [1155.8566242794639, 444.55411179014027], [1007.1614903644768, 471.4415668044468], [1140.8357660333572, 447.1353215665612], [1004.4272990400759, 415.8145743170685], [1113.0236698075012, 493.0951376647424], [1056.7423991153055, 498.9030832850383], [1108.6216025048652, 553.0606874049112], [1016.70009673768, 531.1464394843297], [1091.3548799011594, 661.3385708747687], [1029.0232484040012, 593.0326698396866]], 'keypoint_scores': [0.05135685205459595, 0.051523201167583466, 0.043239131569862366, 0.07411273568868637, 0.025272555649280548, 0.08319014310836792, 0.08766089379787445, 0.05544418841600418, 0.11625349521636963, 0.08027558028697968, 0.0822111964225769, 0.049149829894304276, 0.03555457293987274, 0.04601064324378967, 0.05236241593956947, 0.09269965440034866, 0.018653396517038345], 'bbox': [[990.1485595703125, 356.98291015625, 1177.5067138671875, 719.3704833984375]], 'bbox_score': 1.0, 'instance_id': 2, 'track_id': 1002}])\n"
     ]
    }
   ],
   "source": [
    "data = track_keypoints_with_heuristics(data)\n",
    "print(data['frame_data'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24aa1387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(390, [{'keypoints': [[623.116569494809, 276.58871374999944], [632.0300657182678, 273.26429975043493], [617.213324244178, 275.89828321752134], [652.723818741729, 286.16960966286035], [608.6365766619523, 290.1093789921881], [687.9399624990729, 337.98545105249127], [583.0273832350395, 338.896641384624], [709.1141864235723, 396.6670181435643], [560.640438566923, 407.75919326930034], [723.8945584481885, 433.93101430077877], [539.0682291890646, 444.8229061857852], [660.440203605054, 447.5955943565432], [590.9682451102794, 445.6246015097727], [679.5426441589224, 503.388014915476], [575.1900484220305, 499.49022418594745], [684.0827803298957, 620.3137314261102], [562.2892200664218, 618.7605232335299]], 'keypoint_scores': [0.04641585797071457, 0.04142773523926735, 0.03796147555112839, 0.04945866018533707, 0.029720377177000046, 0.11248690634965897, 0.08959366381168365, 0.12298426777124405, 0.09696049988269806, 0.1587880253791809, 0.12082652747631073, 0.08149617910385132, 0.07353484630584717, 0.07115766406059265, 0.07012289762496948, 0.06569511443376541, 0.07293447852134705], 'bbox': [[502.62579345703125, 241.64248657226562, 760.92529296875, 683.9012451171875]], 'bbox_score': 1.0, 'instance_id': 1, 'track_id': 1001}, {'keypoints': [[1035.3002665288702, 399.8481518098167], [1040.1133215535378, 392.1153783776783], [1032.7280411434638, 399.95551812319843], [1061.4472009103663, 389.5831556676193], [1028.187783714579, 407.55537119198266], [1103.126743480112, 412.77206345398076], [1039.5795192736596, 436.5235398217817], [1155.8566242794639, 444.55411179014027], [1007.1614903644768, 471.4415668044468], [1140.8357660333572, 447.1353215665612], [1004.4272990400759, 415.8145743170685], [1113.0236698075012, 493.0951376647424], [1056.7423991153055, 498.9030832850383], [1108.6216025048652, 553.0606874049112], [1016.70009673768, 531.1464394843297], [1091.3548799011594, 661.3385708747687], [1029.0232484040012, 593.0326698396866]], 'keypoint_scores': [0.05135685205459595, 0.051523201167583466, 0.043239131569862366, 0.07411273568868637, 0.025272555649280548, 0.08319014310836792, 0.08766089379787445, 0.05544418841600418, 0.11625349521636963, 0.08027558028697968, 0.0822111964225769, 0.049149829894304276, 0.03555457293987274, 0.04601064324378967, 0.05236241593956947, 0.09269965440034866, 0.018653396517038345], 'bbox': [[990.1485595703125, 356.98291015625, 1177.5067138671875, 719.3704833984375]], 'bbox_score': 1.0, 'instance_id': 2, 'track_id': 1002}])\n"
     ]
    }
   ],
   "source": [
    "patient_data = extract_main_patient_data(data)\n",
    "print(data['frame_data'][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
